{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3482340-811d-429a-ba1f-80baca631c7e",
   "metadata": {},
   "source": [
    "# Graph Convolutional Network for Link Predition\n",
    "This notebook demonstrates the training of Graph Convolutional Networks for Link Prediction with TigerGraph. Pytorch Geometric's implementation of GCN is used here. We train the model on the Cora dataset from PyG datasets with TigerGraph as the data store. The dataset contains 2708 machine learning papers and 10556 citation links between the papers. Each publication in the dataset is described by a 0/1-valued word vector indicating the absence/presence of the corresponding word from a dictionary. The dictionary consists of 1433 unique words. Each paper is classified into one of seven classes based on the topic. The goal is to predict the class of each vertex in the graph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d786d1fe-3758-4810-8c34-e66e59687a58",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "Here we assume the dataset is already ingested into the TigerGraph database. If not, please refer to the example on data ingestion first.\n",
    "\n",
    "For each edges, the original attributes include \"is_train, is_val\", and you may add \"is_test\" if want have the train/val/test edge sets. Otherwise, for the edgeSplitter, you can just split the train/val sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81383884-2fb9-46f6-9ce6-ad227abf4e52",
   "metadata": {},
   "source": [
    "### Connect to TigerGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea45afd1-4fc3-4bc6-b739-2e89450df296",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyTigerGraph import TigerGraphConnection\n",
    "import torch\n",
    "\n",
    "conn = TigerGraphConnection(\n",
    "    host=\"http://127.0.0.1\", # Change the address to your database server's\n",
    "    graphname=\"Cora\",\n",
    "    username=\"tigergraph\",\n",
    "    password=\"tigergraph\",\n",
    "    useCert=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3c94459-35aa-4e5b-a23a-cfc57b4ecac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Paper': 2708}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.getVertexCount('*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "196ba830-ed69-4b1a-b77d-9aaff54e6d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cite': 10556}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.getEdgeCount('*')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a23f94b-12e9-43c0-8d9c-20046bf59e13",
   "metadata": {},
   "source": [
    "### Train/validation/test split\n",
    "If there are no is_test in the graph, you can add the edge attribute to TigerGraph or split train and val by 0.8 and 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93935b53-cbe4-4838-a570-55b750b1fff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "splitter = conn.gds.edgeSplitter(is_train=0.8, is_val=0.1, is_test=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54abea3e-9f99-4d7a-be06-6aa6630552de",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "splitter.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63bc960-ec54-4755-b372-f40b367abce1",
   "metadata": {},
   "source": [
    "## Train on whole graph\n",
    "Here, we use the full graph for link prediciton. This will **NOT** work when the graph is very large. See the section of Stochastic Mini-Batch Training for real use. However, we still include this example for illustration purpose.\n",
    "\n",
    "We load the whole graph from TigerGraph which include the feature and split results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182afd6a-a68d-4b28-8ac6-86e6a6b51e8f",
   "metadata": {},
   "source": [
    "### Construct graph loader and negative edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2544116b-4169-48ac-bd0f-049dfbcfc00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_loader = conn.gds.graphLoader(\n",
    "    num_batches=1,\n",
    "    v_in_feats = [\"x\"],\n",
    "    e_extra_feats=[\"is_train\",\"is_val\", \"is_test\"],\n",
    "    output_format = \"PyG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "874be99d-9c9b-485c-ad75-7581132780a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = graph_loader.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29a1443b-e53d-4c0d-994d-b3e2a50e8a04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 10556], is_train=[10556], is_val=[10556], is_test=[10556], x=[2708, 1433])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bca4fdb7-94d1-4d46-a041-ad280efeb6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_edge_index = data.edge_index[:, data.is_train]\n",
    "val_edge_index = data.edge_index[:, data.is_val]\n",
    "test_edge_index = data.edge_index[:, data.is_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10410e24-e984-4c4d-9b54-61f66078f3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_val_edge = torch.randint(0, data.x.shape[0], val_edge_index.size(), dtype=torch.long)\n",
    "neg_test_edge = torch.randint(0, data.x.shape[0], test_edge_index.size(), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "abdd6e53-13e0-4299-8fee-b5ee9a90b2d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 8532]), torch.Size([2, 1007]), torch.Size([2, 1007]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_edge_index.shape, val_edge_index.shape, neg_val_edge.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef04bf96-ffc1-45ad-91f8-b490258668a3",
   "metadata": {},
   "source": [
    "### Construct GCN Model\n",
    "We use dot product to measure the similarity of two node in a decode function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4bc349b-4830-4459-bf95-206cbe89d555",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers, dropout, **kwargs):\n",
    "        super(GCN, self).__init__()\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(GCNConv(in_channels, hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(GCNConv(hidden_channels, hidden_channels))\n",
    "        self.convs.append(GCNConv(hidden_channels, out_channels))\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "\n",
    "    def forward(self, x, adj_t):\n",
    "        for i, conv in enumerate(self.convs[:-1]):\n",
    "            x = conv(x, adj_t)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.convs[-1](x, adj_t)\n",
    "        return x\n",
    "\n",
    "    def decode(self, z, pos_edge_index, neg_edge_index):\n",
    "        edge_index = torch.cat([pos_edge_index, neg_edge_index], dim=-1) # concatenate pos and neg edges\n",
    "        logits = (z[edge_index[0]] * z[edge_index[1]]).sum(dim=-1)  # dot product \n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a6bfba-3157-4330-ae6c-49e25a18491e",
   "metadata": {},
   "source": [
    "### Get binary labels for positive and negative edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d5123bd-2ebc-43a6-a9b3-ac0d503c0f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_link_labels(pos_edge_index, neg_edge_index):\n",
    "    E = pos_edge_index.size(1) + neg_edge_index.size(1)\n",
    "    link_labels = torch.zeros(E, dtype=torch.float)\n",
    "    link_labels[:pos_edge_index.size(1)] = 1.\n",
    "    return link_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939e07f7-e6ae-4bea-ad82-3f549ddeba42",
   "metadata": {},
   "source": [
    "### Define Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a631ec03-1a9a-41a0-9734-ab7ff3dea269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "hp = {\"hidden_dim\": 128, \"out_dim\": 64, \"num_layers\": 2,\n",
    "      \"dropout\": 0.6, \"lr\": 0.01, \"l2_penalty\": 5e-4}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db9abec-dc1c-401c-a3f0-7693c768ae3f",
   "metadata": {},
   "source": [
    "### Instantiate Model and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bcbc8fca-6eff-4238-928f-f51eb936496b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCN(1433, hp[\"hidden_dim\"], hp[\"out_dim\"], hp[\"num_layers\"], hp[\"dropout\"])\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr=hp[\"lr\"], weight_decay=hp[\"l2_penalty\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f0e9a355-e46b-4626-8a35-c5360dec07bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.,  ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_labels = get_link_labels(val_edge_index, neg_val_edge)\n",
    "val_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a700bfa-253a-4868-877b-194598b30c07",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5cde228b-fd55-4116-88ad-dbcb787be5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4a894353-20f1-42d0-9d7e-6297a3cb4e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, training loss: 0.652077853679657, valid roc_auc_score: 0.8222595752276272\n",
      "Epoch: 1, training loss: 1.0911240577697754, valid roc_auc_score: 0.813158930189764\n",
      "Epoch: 2, training loss: 1.2042229175567627, valid roc_auc_score: 0.7523507246691234\n",
      "Epoch: 3, training loss: 0.7218725085258484, valid roc_auc_score: 0.7803331002742472\n",
      "Epoch: 4, training loss: 0.6301491856575012, valid roc_auc_score: 0.8178519972900719\n",
      "Epoch: 5, training loss: 0.6423941254615784, valid roc_auc_score: 0.8162573997903454\n",
      "Epoch: 6, training loss: 0.6524781584739685, valid roc_auc_score: 0.8052441252838867\n",
      "Epoch: 7, training loss: 0.6515461802482605, valid roc_auc_score: 0.8135050673093707\n",
      "Epoch: 8, training loss: 0.6498074531555176, valid roc_auc_score: 0.8139863063816444\n",
      "Epoch: 9, training loss: 0.6412517428398132, valid roc_auc_score: 0.8221377862410988\n",
      "Epoch: 10, training loss: 0.6362589597702026, valid roc_auc_score: 0.8369270124027538\n",
      "Epoch: 11, training loss: 0.6336613893508911, valid roc_auc_score: 0.8220598807355464\n",
      "Epoch: 12, training loss: 0.6238747835159302, valid roc_auc_score: 0.849305112474841\n",
      "Epoch: 13, training loss: 0.6148176193237305, valid roc_auc_score: 0.8471957469510841\n",
      "Epoch: 14, training loss: 0.6046363115310669, valid roc_auc_score: 0.8659818213912739\n",
      "Epoch: 15, training loss: 0.5951206088066101, valid roc_auc_score: 0.8773895541536947\n",
      "Epoch: 16, training loss: 0.5858882069587708, valid roc_auc_score: 0.8756894390704986\n",
      "Epoch: 17, training loss: 0.5674903988838196, valid roc_auc_score: 0.872675777994949\n",
      "Epoch: 18, training loss: 0.5609842538833618, valid roc_auc_score: 0.8839987022323379\n",
      "Epoch: 19, training loss: 0.5475088357925415, valid roc_auc_score: 0.8894017941933773\n",
      "Epoch: 20, training loss: 0.5335940718650818, valid roc_auc_score: 0.8822818226732634\n",
      "Epoch: 21, training loss: 0.5321722030639648, valid roc_auc_score: 0.8818370709896661\n",
      "Epoch: 22, training loss: 0.5155735611915588, valid roc_auc_score: 0.8974802992754787\n",
      "Epoch: 23, training loss: 0.5104623436927795, valid roc_auc_score: 0.8912084130056831\n",
      "Epoch: 24, training loss: 0.5082799792289734, valid roc_auc_score: 0.897426061265284\n",
      "Epoch: 25, training loss: 0.5018641948699951, valid roc_auc_score: 0.9039592761296547\n",
      "Epoch: 26, training loss: 0.4956902861595154, valid roc_auc_score: 0.91490253429568\n",
      "Epoch: 27, training loss: 0.4942399263381958, valid roc_auc_score: 0.9096315858503878\n",
      "Epoch: 28, training loss: 0.4901338815689087, valid roc_auc_score: 0.9244217981576828\n",
      "Epoch: 29, training loss: 0.4876100718975067, valid roc_auc_score: 0.9179349321383878\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(30):\n",
    "    model.train()\n",
    "    neg_train_edge = torch.randint(0, data.x.shape[0], train_edge_index.size(), dtype=torch.long)\n",
    "    h = model(data.x.float(), train_edge_index)\n",
    "    logits = model.decode(h, train_edge_index, neg_train_edge)\n",
    "    labels = get_link_labels(train_edge_index, neg_train_edge)\n",
    "    loss = F.binary_cross_entropy_with_logits(logits, labels)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_logits = model.decode(h, val_edge_index, neg_val_edge)\n",
    "        val_logits = val_logits.sigmoid()\n",
    "        print('Epoch: {}, training loss: {}, valid roc_auc_score: {}'.format(epoch, loss.item(), roc_auc_score(val_labels, val_logits)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad2acb3-f850-42aa-8333-ab82733d72bb",
   "metadata": {},
   "source": [
    "## Stochastic Batch Training\n",
    "For stochastic batch training, we split the training edges into batches. At each specific batch, to do the link prediction, we need to know the neighbor graphs for the each pair of nodes that has a edge.\n",
    "\n",
    "We use the edgeNeighborLoader, which can load the neghbors of the pair nodes of a edge and has the same parameters as neighborLoader(). The result of a batch is, for example,\n",
    "\n",
    "`Data(edge_index=[2, 6917], is_train=[6917], is_val=[6917], is_test=[6917], is_seed=[6917], x=[2188, 1433], y=[2188])`\n",
    "\n",
    "where `is_seed` indicates whether each edge is a seed edge or not\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3a41d8aa-55f7-4e31-a2b0-3edcfc1cd73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "hp = {\"hidden_dim\": 128, \"out_dim\": 64, \"num_layers\": 2,\n",
    "      \"dropout\": 0.6, \"lr\": 0.01, \"l2_penalty\": 5e-4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "31f89253-93ca-479b-8d1c-5a06bef9aaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCN(1433, hp[\"hidden_dim\"], hp[\"out_dim\"], hp[\"num_layers\"], hp[\"dropout\"])\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr=hp[\"lr\"], weight_decay=hp[\"l2_penalty\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bb697c-7355-46e0-b6ab-f54750eedb85",
   "metadata": {},
   "source": [
    "### Construct the edge_neighbor_loader for train/val/test edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c2711014-81ce-4ff4-8959-3e251b7bf394",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_edge_neighbor_loader = conn.gds.edgeNeighborLoader(\n",
    "    v_in_feats=[\"x\"],\n",
    "    v_out_labels=[\"y\"],\n",
    "    num_batches=5,\n",
    "    e_extra_feats=[\"is_train\",\"is_val\", \"is_test\"],\n",
    "    output_format=\"PyG\",\n",
    "    num_neighbors=10,\n",
    "    num_hops=2,\n",
    "    filter_by=\"is_train\",\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7e02ab37-dcf2-4681-971d-04a2ae8ed0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_edge_neighbor_loader = conn.gds.edgeNeighborLoader(\n",
    "    v_in_feats=[\"x\"],\n",
    "    v_out_labels=[\"y\"],\n",
    "    num_batches=5,\n",
    "    e_extra_feats=[\"is_train\",\"is_val\", \"is_test\"],\n",
    "    output_format=\"PyG\",\n",
    "    num_neighbors=10,\n",
    "    num_hops=2,\n",
    "    filter_by=\"is_val\",\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2bd6ab8a-a266-48f5-97ae-38aab5a2bab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, training loss: 3.0831108689308167, valid roc_auc_score: 0.8723227378558631\n",
      "Epoch: 1, training loss: 2.9560742378234863, valid roc_auc_score: 0.909797258317892\n",
      "Epoch: 2, training loss: 2.6730599403381348, valid roc_auc_score: 0.928123788889886\n",
      "Epoch: 3, training loss: 2.4813827872276306, valid roc_auc_score: 0.934900581727313\n",
      "Epoch: 4, training loss: 2.358451873064041, valid roc_auc_score: 0.940606420399803\n",
      "Epoch: 5, training loss: 2.3540602326393127, valid roc_auc_score: 0.9591291939541384\n",
      "Epoch: 6, training loss: 2.264620155096054, valid roc_auc_score: 0.9612563100994135\n",
      "Epoch: 7, training loss: 2.265827476978302, valid roc_auc_score: 0.9633173544868149\n",
      "Epoch: 8, training loss: 2.223086267709732, valid roc_auc_score: 0.9682091299335635\n",
      "Epoch: 9, training loss: 2.237872064113617, valid roc_auc_score: 0.9637492862770931\n",
      "Epoch: 10, training loss: 2.2264839708805084, valid roc_auc_score: 0.9678171370417011\n",
      "Epoch: 11, training loss: 2.2111732065677643, valid roc_auc_score: 0.955345353133823\n",
      "Epoch: 12, training loss: 2.201561450958252, valid roc_auc_score: 0.9662817082803691\n",
      "Epoch: 13, training loss: 2.1999124884605408, valid roc_auc_score: 0.9693949700655491\n",
      "Epoch: 14, training loss: 2.203977555036545, valid roc_auc_score: 0.9574852891724167\n",
      "Epoch: 15, training loss: 2.2005884647369385, valid roc_auc_score: 0.9696868691749609\n",
      "Epoch: 16, training loss: 2.187116324901581, valid roc_auc_score: 0.9705260791145199\n",
      "Epoch: 17, training loss: 2.19451966881752, valid roc_auc_score: 0.9747033920451575\n",
      "Epoch: 18, training loss: 2.1870830059051514, valid roc_auc_score: 0.9700754105570836\n",
      "Epoch: 19, training loss: 2.184099942445755, valid roc_auc_score: 0.9742127845893047\n",
      "Epoch: 20, training loss: 2.17471045255661, valid roc_auc_score: 0.9730624457003558\n",
      "Epoch: 21, training loss: 2.17342272400856, valid roc_auc_score: 0.975352275876215\n",
      "Epoch: 22, training loss: 2.145278960466385, valid roc_auc_score: 0.9693180507056365\n",
      "Epoch: 23, training loss: 2.1720694601535797, valid roc_auc_score: 0.9709185650792024\n",
      "Epoch: 24, training loss: 2.1501611173152924, valid roc_auc_score: 0.969572476280732\n",
      "Epoch: 25, training loss: 2.1431657671928406, valid roc_auc_score: 0.9742546957790009\n",
      "Epoch: 26, training loss: 2.1697450280189514, valid roc_auc_score: 0.9719648656031414\n",
      "Epoch: 27, training loss: 2.140758454799652, valid roc_auc_score: 0.9688008173175063\n",
      "Epoch: 28, training loss: 2.149218201637268, valid roc_auc_score: 0.9687894766426476\n",
      "Epoch: 29, training loss: 2.153587430715561, valid roc_auc_score: 0.9725388023655661\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(30):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for bid, batch in enumerate(train_edge_neighbor_loader):\n",
    "        # get the training edges and negative edges sampled in the same batch\n",
    "        train_edges = batch.edge_index[:, batch.is_seed]\n",
    "        neg_train_edges = torch.randint(0, batch.x.shape[0], train_edges.size(), dtype=torch.long)\n",
    "        # The graph only include the edges whose is_train is True\n",
    "        train_graph_edges = batch.edge_index[:, batch.is_train]\n",
    "        h = model(batch.x.float(), train_graph_edges)\n",
    "        logits = model.decode(h, train_edges, neg_train_edges)\n",
    "        labels = get_link_labels(train_edges, neg_train_edges)\n",
    "        loss = F.binary_cross_entropy_with_logits(logits, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_logits = []\n",
    "    for batch in val_edge_neighbor_loader:\n",
    "        val_edges = batch.edge_index[:, batch.is_seed]\n",
    "        neg_val_edges = torch.randint(0, batch.x.shape[0], val_edges.size(), dtype=torch.long)\n",
    "        # Need to use the train edge for GCN\n",
    "        val_graph_edges = batch.edge_index[:, batch.is_train]\n",
    "        with torch.no_grad():\n",
    "            h = model(batch.x.float(), val_graph_edges)\n",
    "            logits = model.decode(h, val_edges, neg_val_edges)\n",
    "            labels = get_link_labels(val_edges, neg_val_edges)\n",
    "            logits = logits.sigmoid()\n",
    "            all_labels.extend(labels)\n",
    "            all_logits.extend(logits)\n",
    "    print('Epoch: {}, training loss: {}, valid roc_auc_score: {}'.format(epoch, total_loss, roc_auc_score(all_labels, all_logits)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca8f8df-e966-4c91-845e-03c2161ad8fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
