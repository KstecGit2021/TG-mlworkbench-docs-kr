{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31a41fec-c7f0-4752-b57a-efb428327343",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d51c63-ed05-43d4-9e02-7d13763b5011",
   "metadata": {},
   "source": [
    "This notebook demonstrates the use of neighbor loader in `pyTigerGraph`. The job of a data loader is to pull data from the TigerGraph database. Currently, the following data loaders are provided:\n",
    "* EdgeLoader, which returns batches of edges.\n",
    "* VertexLoader, which returns batches of vertices.\n",
    "* GraphLoader, which returns randomly sampled (probably disconnected) subgraphs in pandas `dataframe`, `PyG` or `DGL` format.\n",
    "* NeighborLoader, which returns subgraphs using neighbor sampling in `dataframe`, `PyG` or `DGL` format.\n",
    "\n",
    "Every data loader above can either get all the batches as a HTTP response (default) or stream every batch through Kafka. The former mechanism is good for testing with small graphs and it is fast, but it subjects to a data size limit of 2GB. For large graphs, the HTTP channel will likely fail due to size limit and network connectivity issues. Streaming via Kafka is offered for data robustness and scalability. Also, Kafka excels at multi-consumer use cases, and it is efficient for model search or hyperparameter tuning when there are multiiple consumers of the same data. \n",
    "\n",
    "Note: For the data loaders to work, a few UDFs (User Defined Functions) have to be installed into the TigerGraph database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9243a4-69ae-4a04-ab82-dc6d393e0cb7",
   "metadata": {},
   "source": [
    "### Connection to Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff08e15-5d93-4f30-8a9d-6b101b1604e4",
   "metadata": {},
   "source": [
    "The `TigerGraphConnection` class represents a connection to the TigerGraph database. Under the hood, it stores the necessary information to communicate with the database. It is able to perform quite a few database tasks. Please see its documentation for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b94e2237-5050-4c58-91de-c86b804d19f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyTigerGraph import TigerGraphConnection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2c4b1e8-a0e2-4026-9bb1-218cdc7ca4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = TigerGraphConnection(\n",
    "    host=\"http://127.0.0.1\", # Change the address to your database server's\n",
    "    graphname=\"Cora\",\n",
    "    username=\"tigergraph\",\n",
    "    password=\"tigergraph\",\n",
    "    useCert=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1dd0252-a5e5-47ee-acce-b843571c78cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Paper': 2708}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of vertices for every vertex type\n",
    "conn.getVertexCount('*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "318f1998-1179-4ae2-9f1b-d1b032076c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cite': 10556}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of edges for every type\n",
    "conn.getEdgeCount()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54f29ef-6b65-4999-9363-f9dfde5e478c",
   "metadata": {},
   "source": [
    "### Neighbor Loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9141a8d2-2a4d-4ced-b4ab-17b5e7604994",
   "metadata": {},
   "source": [
    "NeighborLoader performs neighbor sampling as introduced in [Inductive Representation Learning on Large Graphs](https://arxiv.org/abs/1706.02216) and returns neighborhood subgraphs. Hence, the subgraphs from this loader are connected. \n",
    "\n",
    "Specifically, the loader first chooses `batch_size` number of vertices as seeds, then picks `num_neighbors` number of neighbors of each seed at random, then `num_neighbors` neighbors of each neighbor, and repeat for `num_hops`. This generates one subgraph. As you loop through this data loader, every vertex will at some point be chosen as a seed and you will get the subgraph expanded from the seed. If you want to limit seeds to certain vertices, the boolean attribute provided to `filter_by` will be used to indicate which vertices can be included as seeds.\n",
    "\n",
    "**Note**: For the first time you initialize the loader on a graph in TigerGraph,\n",
    "the initialization might take a minute as it installs the corresponding\n",
    "query to the database and optimizes it. However, the query installation only\n",
    "needs to be done once, so it will take no time when you initialize the loader\n",
    "on the same TG graph again.\n",
    "\n",
    "There are two ways to use the data loader. See\n",
    "[here](https://github.com/TigerGraph-DevLabs/mlworkbench-docs/blob/main/tutorials/basics/2_dataloaders.ipynb)\n",
    "for examples.\n",
    "* First, it can be used as an iterable, which means you can loop through\n",
    "  it to get every batch of data. If you load all data at once (`num_batches=1`),\n",
    "  there will be only one batch (of all the data) in the iterator.\n",
    "* Second, you can access the `data` property of the class directly. If there is\n",
    "  only one batch of data to load, it will give you the batch directly instead\n",
    "  of an iterator, which might make more sense in that case. If there are\n",
    "  multiple batches of data to load, it will return the loader itself.\n",
    "    \n",
    "Args:\n",
    "* attributes (list, optional):\n",
    "        Edge attributes to be included. Defaults to None.\n",
    "* batch_size (int, optional):  \n",
    "        Number of edges in each batch.  \n",
    "        Defaults to None.  \n",
    "* num_batches (int, optional):  \n",
    "        Number of batches to split the edges.  \n",
    "        Defaults to 1.  \n",
    "* num_neighbors (int, optional):\n",
    "        Number of neighbors to sample for each vertex.\n",
    "        Defaults to 10.\n",
    "* num_hops (int, optional):\n",
    "        Number of hops to traverse when sampling neighbors.\n",
    "        Defaults to 2.\n",
    "* shuffle (bool, optional):  \n",
    "        Whether to shuffle the edges before loading data.  \n",
    "        Defaults to False.  \n",
    "* filter_by (str, optional):\n",
    "        A boolean attribute used to indicate which edges are included. Defaults to None.\n",
    "* output_format (str, optional):\n",
    "        Format of the output data of the loader. Only\n",
    "        \"dataframe\" is supported. Defaults to \"dataframe\".\n",
    "* loader_id (str, optional):\n",
    "        An identifier of the loader which can be any string. It is\n",
    "        also used as the Kafka topic name. If `None`, a random string will be generated\n",
    "        for it. Defaults to None.\n",
    "* buffer_size (int, optional):\n",
    "        Number of data batches to prefetch and store in memory. Defaults to 4.\n",
    "* kafka_address (str, optional):\n",
    "        Address of the kafka broker. Defaults to None.\n",
    "* kafka_max_msg_size (int, optional):\n",
    "        Maximum size of a Kafka message in bytes.\n",
    "        Defaults to 104857600.\n",
    "* kafka_num_partitions (int, optional):\n",
    "        Number of partitions for the topic created by this loader.\n",
    "        Defaults to 1.\n",
    "* kafka_replica_factor (int, optional):\n",
    "        Number of replications for the topic created by this\n",
    "        loader. Defaults to 1.\n",
    "* kafka_retention_ms (int, optional):\n",
    "        Retention time for messages in the topic created by this\n",
    "        loader in milliseconds. Defaults to 60000.\n",
    "* kafka_auto_del_topic (bool, optional):\n",
    "        Whether to delete the Kafka topic once the\n",
    "        loader finishes pulling data. Defaults to True.\n",
    "* kafka_address_consumer (str, optional):\n",
    "        Address of the kafka broker that a consumer\n",
    "        should use. Defaults to be the same as `kafkaAddress`.\n",
    "* kafka_address_producer (str, optional):\n",
    "        Address of the kafka broker that a producer\n",
    "        should use. Defaults to be the same as `kafkaAddress`.\n",
    "* timeout (int, optional):\n",
    "        Timeout value for GSQL queries, in ms. Defaults to 300000."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fc6fb4-9e7b-4d7a-8c97-aa5d43b18468",
   "metadata": {},
   "source": [
    "#### Get subgraphs through http"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "269bf653-ea3a-4646-aa0d-ef539838a7cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing and optimizing queries. It might take a minute if this is the first time you use this loader.\n",
      "Query installation finished.\n",
      "CPU times: user 24.8 ms, sys: 8.31 ms, total: 33.1 ms\n",
      "Wall time: 42.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "neighbor_loader = conn.gds.neighborLoader(\n",
    "    num_batches=10,\n",
    "    num_neighbors = 10,\n",
    "    num_hops =2,\n",
    "    v_in_feats = [\"x\"],\n",
    "    v_out_labels = [\"y\"],\n",
    "    v_extra_feats = [\"train_mask\", \"val_mask\", \"test_mask\"],\n",
    "    e_in_feats=[\"time\"],\n",
    "    e_out_labels=[],\n",
    "    e_extra_feats=[\"is_train\", \"is_val\"],\n",
    "    output_format = \"PyG\",\n",
    "    shuffle=True,\n",
    "    filter_by=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc82350c-9e80-4ff1-8c1b-67ae60a75a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tigergraph/conda/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Batch 0----\n",
      "Data(edge_index=[2, 12710], edge_feat=[12710], is_train=[12710], is_val=[12710], x=[2055, 1433], y=[2055], train_mask=[2055], val_mask=[2055], test_mask=[2055], is_seed=[2055])\n",
      "----Batch 1----\n",
      "Data(edge_index=[2, 11142], edge_feat=[11142], is_train=[11142], is_val=[11142], x=[2035, 1433], y=[2035], train_mask=[2035], val_mask=[2035], test_mask=[2035], is_seed=[2035])\n",
      "----Batch 2----\n",
      "Data(edge_index=[2, 12686], edge_feat=[12686], is_train=[12686], is_val=[12686], x=[2105, 1433], y=[2105], train_mask=[2105], val_mask=[2105], test_mask=[2105], is_seed=[2105])\n",
      "----Batch 3----\n",
      "Data(edge_index=[2, 12012], edge_feat=[12012], is_train=[12012], is_val=[12012], x=[2072, 1433], y=[2072], train_mask=[2072], val_mask=[2072], test_mask=[2072], is_seed=[2072])\n",
      "----Batch 4----\n",
      "Data(edge_index=[2, 11406], edge_feat=[11406], is_train=[11406], is_val=[11406], x=[2047, 1433], y=[2047], train_mask=[2047], val_mask=[2047], test_mask=[2047], is_seed=[2047])\n",
      "----Batch 5----\n",
      "Data(edge_index=[2, 11842], edge_feat=[11842], is_train=[11842], is_val=[11842], x=[2098, 1433], y=[2098], train_mask=[2098], val_mask=[2098], test_mask=[2098], is_seed=[2098])\n",
      "----Batch 6----\n",
      "Data(edge_index=[2, 12202], edge_feat=[12202], is_train=[12202], is_val=[12202], x=[2069, 1433], y=[2069], train_mask=[2069], val_mask=[2069], test_mask=[2069], is_seed=[2069])\n",
      "----Batch 7----\n",
      "Data(edge_index=[2, 10044], edge_feat=[10044], is_train=[10044], is_val=[10044], x=[2012, 1433], y=[2012], train_mask=[2012], val_mask=[2012], test_mask=[2012], is_seed=[2012])\n",
      "----Batch 8----\n",
      "Data(edge_index=[2, 11456], edge_feat=[11456], is_train=[11456], is_val=[11456], x=[2049, 1433], y=[2049], train_mask=[2049], val_mask=[2049], test_mask=[2049], is_seed=[2049])\n",
      "----Batch 9----\n",
      "Data(edge_index=[2, 10942], edge_feat=[10942], is_train=[10942], is_val=[10942], x=[2025, 1433], y=[2025], train_mask=[2025], val_mask=[2025], test_mask=[2025], is_seed=[2025])\n",
      "CPU times: user 23.1 s, sys: 1.12 s, total: 24.2 s\n",
      "Wall time: 7.56 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i, batch in enumerate(neighbor_loader):\n",
    "    print(\"----Batch {}----\".format(i))\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8dd1f1-9139-4f7a-b10f-3ecd60226541",
   "metadata": {},
   "source": [
    "#### Get subgraphs through kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae1a869d-6b10-4f48-8fae-adc757e757cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:kafka.coordinator.consumer:group_id is None: disabling auto-commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing and optimizing queries. It might take a minute if this is the first time you use this loader.\n",
      "Query installation finished.\n",
      "CPU times: user 41.3 ms, sys: 10 ms, total: 51.3 ms\n",
      "Wall time: 30.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "neighbor_loader = conn.gds.neighborLoader(\n",
    "    num_batches=10,\n",
    "    num_neighbors = 10,\n",
    "    num_hops =2,\n",
    "    v_in_feats = [\"x\"],\n",
    "    v_out_labels = [\"y\"],\n",
    "    v_extra_feats = [\"train_mask\", \"val_mask\", \"test_mask\"],\n",
    "    e_in_feats=[\"time\"],\n",
    "    e_out_labels=[],\n",
    "    e_extra_feats=[\"is_train\", \"is_val\"],\n",
    "    output_format = \"PyG\",\n",
    "    shuffle=True,\n",
    "    filter_by=None,\n",
    "    kafka_address=\"127.0.0.1:9092\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d375539a-7b5c-4fe9-ab3e-53a78c9a2845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Batch 0----\n",
      "Data(edge_index=[2, 11032], edge_feat=[11032], is_train=[11032], is_val=[11032], x=[2042, 1433], y=[2042], train_mask=[2042], val_mask=[2042], test_mask=[2042], is_seed=[2042])\n",
      "----Batch 1----\n",
      "Data(edge_index=[2, 11586], edge_feat=[11586], is_train=[11586], is_val=[11586], x=[2095, 1433], y=[2095], train_mask=[2095], val_mask=[2095], test_mask=[2095], is_seed=[2095])\n",
      "----Batch 2----\n",
      "Data(edge_index=[2, 13256], edge_feat=[13256], is_train=[13256], is_val=[13256], x=[2116, 1433], y=[2116], train_mask=[2116], val_mask=[2116], test_mask=[2116], is_seed=[2116])\n",
      "----Batch 3----\n",
      "Data(edge_index=[2, 12180], edge_feat=[12180], is_train=[12180], is_val=[12180], x=[2063, 1433], y=[2063], train_mask=[2063], val_mask=[2063], test_mask=[2063], is_seed=[2063])\n",
      "----Batch 4----\n",
      "Data(edge_index=[2, 11840], edge_feat=[11840], is_train=[11840], is_val=[11840], x=[2044, 1433], y=[2044], train_mask=[2044], val_mask=[2044], test_mask=[2044], is_seed=[2044])\n",
      "----Batch 5----\n",
      "Data(edge_index=[2, 11422], edge_feat=[11422], is_train=[11422], is_val=[11422], x=[2076, 1433], y=[2076], train_mask=[2076], val_mask=[2076], test_mask=[2076], is_seed=[2076])\n",
      "----Batch 6----\n",
      "Data(edge_index=[2, 11518], edge_feat=[11518], is_train=[11518], is_val=[11518], x=[2055, 1433], y=[2055], train_mask=[2055], val_mask=[2055], test_mask=[2055], is_seed=[2055])\n",
      "----Batch 7----\n",
      "Data(edge_index=[2, 10424], edge_feat=[10424], is_train=[10424], is_val=[10424], x=[2033, 1433], y=[2033], train_mask=[2033], val_mask=[2033], test_mask=[2033], is_seed=[2033])\n",
      "----Batch 8----\n",
      "Data(edge_index=[2, 11964], edge_feat=[11964], is_train=[11964], is_val=[11964], x=[2127, 1433], y=[2127], train_mask=[2127], val_mask=[2127], test_mask=[2127], is_seed=[2127])\n",
      "----Batch 9----\n",
      "Data(edge_index=[2, 12504], edge_feat=[12504], is_train=[12504], is_val=[12504], x=[2127, 1433], y=[2127], train_mask=[2127], val_mask=[2127], test_mask=[2127], is_seed=[2127])\n",
      "CPU times: user 21.9 s, sys: 999 ms, total: 22.9 s\n",
      "Wall time: 5.77 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i, batch in enumerate(neighbor_loader):\n",
    "    print(\"----Batch {}----\".format(i))\n",
    "    print(batch)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-9.m81",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-9:m81"
  },
  "kernelspec": {
   "display_name": "Tigergraph Pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc-autonumbering": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
