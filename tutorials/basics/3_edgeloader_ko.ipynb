{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31a41fec-c7f0-4752-b57a-efb428327343",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 데이터 로더(Data Loaders)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d51c63-ed05-43d4-9e02-7d13763b5011",
   "metadata": {},
   "source": [
    "이 노트북은 `pyTigerGraph` 에서 **edge loader** 의 사용을 보여줍니다. 데이터 로더의 역할은 `TigerGraph` 데이터베이스에서 데이터를 가져오는 것입니다. 현재 다음 데이터 로더가 제공됩니다.\n",
    "\n",
    "* EdgeLoader, 간선의 배치(batch)를 반환합니다.\n",
    "* VertexLoader, 정점의 배치(batch)를 반환합니다.\n",
    "* GraphLoader, 무작위로 샘플링된(연결이 끊긴) 하위 그래프(subgraphs)를 pandas의 `dataframe`, `PyG` 또는 `DGL` 형식으로 반환 합니다.\n",
    "* NeighborLoader, 이웃 샘플링을 사용하여 하위 그래프(subgraphs)를 `dataframe`, `PyG` 또는 `DGL`  형식으로 반환 합니다.\n",
    "* EdgeNeighborLoader, 간선들에서 이웃 샘플링을 사용하여 하위 그래프(subgraphs)를 `dataframe`, `PyG` 또는 `DGL` 형식으로 반환 합니다.\n",
    "\n",
    "위의 모든 데이터 로더는 모든 배치를 HTTP 응답(기본값)으로 가져오거나 Kafka를 통해 모든 배치를 스트리밍할 수 있습니다. 전자의 메커니즘은 작은 그래프로 테스트하기에 좋고 빠르지만 데이터 크기 제한이 2GB입니다. 큰 그래프의 경우 크기 제한 및 네트워크 연결 문제로 인해 HTTP 채널이 실패할 수 있습니다. Kafka를 통한 스트리밍은 데이터 견고성과 확장성을 위해 제공됩니다. 또한 Kafka는 다중 소비자(multi-consumer) 사용 사례에 탁월하며 동일한 데이터의 다중 소비자가 있는 경우 모델 검색 또는 하이퍼파라미터 튜닝에 효율적입니다.\n",
    "\n",
    "데이터 로더는 동종 및 이종 그래프를 모두 지원합니다. 기본적으로 모든 정점 및 간선 유형에서 로드하고 그래프를 동종 그래프로 처리합니다. 그러나 사용자가 로드할 정점 및 간선 유형과 각 유형에서 로드할 속성을 지정할 수도 있습니다. 이 방법으로 사용자는 이기종 그래프 출력을 얻을 수 있습니다.\n",
    "\n",
    "**NOTE**: 현재 ML Workbench에서 제공하는 모든 기능을 사용하려면 데이터베이스를 한 번만 활성화(activage)해야 합니다. ML Workbench on Cloud를 사용하는 경우 activator가 포함되며 아래 셀을 실행(먼저 주석 해제)하여 활성화(activage)할 수 있습니다. 다른 버전의 Workbench의 경우 https://act.tigergraphlabs.com 에서 활성기(activator)를 다운로드할 수 있습니다. 자세한 지침은 해당 웹사이트에도 포함되어 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6921288b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아래 주석을 제거하고 필요한 정보를 입력하십시오. 자세한 지침은 https://act.tigergraphlabs.com을 참조하십시오.\n",
    "# !mlwb activate [데이터베이스 주소] -u [사용자 이름] -p [비밀번호] -s [비밀]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9243a4-69ae-4a04-ab82-dc6d393e0cb7",
   "metadata": {},
   "source": [
    "### 데이터베이스 연결 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff08e15-5d93-4f30-8a9d-6b101b1604e4",
   "metadata": {},
   "source": [
    "이 `TigerGraphConnection` 클래스는 TigerGraph 데이터베이스에 대한 연결을 나타냅니다. 후드 아래에는 데이터베이스와 통신하는 데 필요한 정보가 저장됩니다. 꽤 많은 데이터베이스 작업을 수행할 수 있습니다. 자세한 내용은 해당 [문서](https://docs.tigergraph.com/pytigergraph/current/intro/) 를 참조하십시오.\n",
    "\n",
    "**Note**: 2022년 7월 5일 이후에 생성된 TG 클라우드 DB는 사용자 이름/비밀번호 대신 비밀 번호가 필요합니다. 그렇지 않으면 비워 둘 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b94e2237-5050-4c58-91de-c86b804d19f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyTigerGraph import TigerGraphConnection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2c4b1e8-a0e2-4026-9bb1-218cdc7ca4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = TigerGraphConnection(\n",
    "    host=\"http://127.0.0.1\", # 데이터베이스 서버의 주소로 변경\n",
    "    graphname=\"Cora\",\n",
    "    username=\"tigergraph\",\n",
    "    password=\"tigergraph\",\n",
    "    gsqlSecret=\"\" # 2022년 7월 5일 이후에 생성된 TG 클라우드 DB에는 user/pass 대신 secret이 필요합니다.  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d395df",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">아래 셀의 주석을 제거하고 토큰 인증이 활성화된 경우 토큰을 가져오고 설정하기 위해 실행합니다.</span>. \n",
    "* 이것은 tgcloud의 모든 데이터베이스에 필요합니다.\n",
    "* `<secret>`은 사용자 암호입니다. 자세한 내용은 https://docs.tigergraph.com/tigergraph-server/current/user-access/managing-credentials#_secrets 를 참조하세요.\n",
    "* secret을 모르는 경우  `secret=conn.createSecret()`를 사용하여 secret을 만들 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d143cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conn.getToken(<secret>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1dd0252-a5e5-47ee-acce-b843571c78cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Paper': 2708}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모든 정점 유형에 대한 정점 수\n",
    "conn.getVertexCount('*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "318f1998-1179-4ae2-9f1b-d1b032076c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cite': 10556}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모든 간선 유형에 대한 간선 수\n",
    "conn.getEdgeCount()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54f29ef-6b65-4999-9363-f9dfde5e478c",
   "metadata": {},
   "source": [
    "### 에지 로더 (Edge Loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9141a8d2-2a4d-4ced-b4ab-17b5e7604994",
   "metadata": {},
   "source": [
    "`EdgeLoader` pulls batches of edges from database. Specifically, it divides edges into `num_batches` and returns each batch separately. The boolean attribute provided to `filter_by` indicates which edges are included. If you need random batches, set `shuffle` to True.\n",
    "\n",
    "**Note**: For the first time you initialize the loader on a graph in TigerGraph,\n",
    "the initialization might take a minute as it installs the corresponding\n",
    "query to the database and optimizes it. However, the query installation only\n",
    "needs to be done once, so it will take no time when you initialize the loader\n",
    "on the same TG graph again.\n",
    "\n",
    "There are two ways to use the data loader. See\n",
    "[here](https://github.com/TigerGraph-DevLabs/mlworkbench-docs/blob/main/tutorials/basics/2_dataloaders.ipynb) for examples.\n",
    "* First, it can be used as an iterable, which means you can loop through it to get every batch of data. If you load all edges at once (`num_batches=1`), there will be only one batch (of all the edges) in the iterator.\n",
    "* Second, you can access the `data` property of the class directly. If there is only one batch of data to load, it will give you the batch directly instead of an iterator, which might make more sense in that case. If there are multiple batches of data to load, it will return the loader again.\n",
    "\n",
    "Args:\n",
    "* attributes (list or dict, optional):\n",
    "        Edge attributes to be included. If it is a list, then the attributes\n",
    "        in the list from all edge types will be selected. An error will be thrown if\n",
    "        certain attribute doesn't exist in all edge types. If it is a dict, keys of the \n",
    "        dict are edge types to be selected, and values are lists of attributes to be \n",
    "        selected for each edge type. Defaults to None.\n",
    "* batch_size (int, optional):  \n",
    "        Number of edges in each batch.  \n",
    "        Defaults to None.  \n",
    "* num_batches (int, optional):  \n",
    "        Number of batches to split the edges.  \n",
    "        Defaults to 1.  \n",
    "* shuffle (bool, optional):  \n",
    "        Whether to shuffle the edges before loading data.  \n",
    "        Defaults to False.  \n",
    "* filter_by (str, optional):\n",
    "        A boolean attribute used to indicate which edges are included. Defaults to None.\n",
    "* output_format (str, optional):\n",
    "        Format of the output data of the loader. Only\n",
    "        \"dataframe\" is supported. Defaults to \"dataframe\".\n",
    "* loader_id (str, optional):\n",
    "        An identifier of the loader which can be any string. It is\n",
    "        also used as the Kafka topic name. If `None`, a random string will be generated\n",
    "        for it. Defaults to None.\n",
    "* buffer_size (int, optional):\n",
    "        Number of data batches to prefetch and store in memory. Defaults to 4.\n",
    "* timeout (int, optional):\n",
    "        Timeout value for GSQL queries, in ms. Defaults to 300000."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eef99ed",
   "metadata": {},
   "source": [
    "`EdgeLoader`는 데이터베이스에서 가장자리 배치를 가져옵니다. 특히 간선을 `num_batches`로 분할 하고 각 배치를 개별적으로 반환합니다. `filter_by`에 제공된 부울 속성은 포함된 가선을 나타냅니다. 임의 배치가 필요한 경우 `shuffle`을 True로 설정하십시오.\n",
    "\n",
    "**Note**: TigerGraph의 그래프에서 로더를 처음 초기화하는 경우 해당 쿼리를 데이터베이스에 설치하고 최적화하므로 초기화에 1분이 걸릴 수 있습니다. 하지만 쿼리 설치는 한 번만 하면 되므로 동일한 TG 그래프에서 다시 로더를 초기화할 때 시간이 걸리지 않습니다.\n",
    "\n",
    "데이터 로더를 사용하는 방법에는 두 가지가 있습니다. 예를 보려면 [여기](https://github.com/TigerGraph-DevLabs/mlworkbench-docs/blob/main/tutorials/basics/2_dataloaders.ipynb) 를 참조 하십시오.\n",
    "\n",
    "* 첫째, iterable로 사용할 수 있습니다. 즉, 루프를 통해 모든 데이터 배치를 가져올 수 있습니다. 모든 에지를 한 번에 로드하면(`num_batches=1`), 반복자에는 (모든 에지 중) 배치가 하나만 있습니다.\n",
    "* 둘째, 클래스의 `data`속성에 직접 액세스할 수 있습니다. 로드할 데이터 배치가 하나만 있는 경우 반복자 대신 배치를 직접 제공하므로 이 경우 더 합리적일 수 있습니다. 로드할 데이터 배치가 여러 개인 경우 로더를 다시 반환합니다.\n",
    "\n",
    "\n",
    "\n",
    "인수(Args):@@@@\n",
    "* attributes (list or dict, optional):\n",
    "        Edge attributes to be included. If it is a list, then the attributes\n",
    "        in the list from all edge types will be selected. An error will be thrown if\n",
    "        certain attribute doesn't exist in all edge types. If it is a dict, keys of the \n",
    "        dict are edge types to be selected, and values are lists of attributes to be \n",
    "        selected for each edge type. Defaults to None.\n",
    "* batch_size (int, optional):  \n",
    "        Number of edges in each batch.  \n",
    "        Defaults to None.  \n",
    "* num_batches (int, optional):  \n",
    "        Number of batches to split the edges.  \n",
    "        Defaults to 1.  \n",
    "* shuffle (bool, optional):  \n",
    "        Whether to shuffle the edges before loading data.  \n",
    "        Defaults to False.  \n",
    "* filter_by (str, optional):\n",
    "        A boolean attribute used to indicate which edges are included. Defaults to None.\n",
    "* output_format (str, optional):\n",
    "        Format of the output data of the loader. Only\n",
    "        \"dataframe\" is supported. Defaults to \"dataframe\".\n",
    "* loader_id (str, optional):\n",
    "        An identifier of the loader which can be any string. It is\n",
    "        also used as the Kafka topic name. If `None`, a random string will be generated\n",
    "        for it. Defaults to None.\n",
    "* buffer_size (int, optional):\n",
    "        Number of data batches to prefetch and store in memory. Defaults to 4.\n",
    "* timeout (int, optional):\n",
    "        Timeout value for GSQL queries, in ms. Defaults to 300000."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853a985e-2686-496a-8d5b-7f413ebf435a",
   "metadata": {},
   "source": [
    "#### Load all edges at once directly to local. Default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f03830f8-07c9-4d94-b7bd-5489ec7104cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing and optimizing queries. It might take a minute if this is the first time you use this loader.\n",
      "Query installation finished.\n",
      "CPU times: user 227 ms, sys: 48.6 ms, total: 276 ms\n",
      "Wall time: 45.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "edge_loader = conn.gds.edgeLoader(\n",
    "    num_batches=1,\n",
    "    attributes=[\"time\", \"is_train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ef47555-b7b3-4db4-abd6-a9f17f1538f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.9 ms, sys: 3.22 ms, total: 15.1 ms\n",
      "Wall time: 36.8 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10556, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Get the only batch of data via the `data` property\n",
    "data = edge_loader.data\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a75e404-ed20-47dd-830d-8eea8c9e82d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>time</th>\n",
       "      <th>is_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10485760</td>\n",
       "      <td>14680110</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10485761</td>\n",
       "      <td>1048637</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10485761</td>\n",
       "      <td>32505881</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10485762</td>\n",
       "      <td>12583005</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10485763</td>\n",
       "      <td>14680101</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     source    target  time  is_train\n",
       "0  10485760  14680110     0         0\n",
       "1  10485761   1048637     0         1\n",
       "2  10485761  32505881     0         1\n",
       "3  10485762  12583005     0         0\n",
       "4  10485763  14680101     0         1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad44dea5-d5ba-495d-9ca5-2f968f0c8ae5",
   "metadata": {},
   "source": [
    "#### Get batches of edges through http"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecea0bdb-f2d2-4efe-b7cf-e46493f76edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.46 ms, sys: 1.35 ms, total: 5.81 ms\n",
      "Wall time: 8.78 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "edge_loader = conn.gds.edgeLoader(\n",
    "    num_batches=10,\n",
    "    attributes=[\"time\", \"is_train\"],\n",
    "    shuffle=True,\n",
    "    filter_by=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87ae37fd-f451-48de-ae02-375d10d18fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Batch 0: Shape (1010, 4)----\n",
      "    source    target  time  is_train\n",
      "0  1048576  23068756     0         1\n",
      "----Batch 1: Shape (1119, 4)----\n",
      "    source    target  time  is_train\n",
      "0  4194309  31457366     0         1\n",
      "----Batch 2: Shape (1072, 4)----\n",
      "     source    target  time  is_train\n",
      "0  10485763  14680101     0         1\n",
      "----Batch 3: Shape (1008, 4)----\n",
      "    source    target  time  is_train\n",
      "0  4194310  20971534     0         0\n",
      "----Batch 4: Shape (1115, 4)----\n",
      "     source   target  time  is_train\n",
      "0  11534338  3145787     0         0\n",
      "----Batch 5: Shape (983, 4)----\n",
      "    source    target  time  is_train\n",
      "0  3145737  18874400     0         1\n",
      "----Batch 6: Shape (1103, 4)----\n",
      "    source    target  time  is_train\n",
      "0  7340042  26214420     0         1\n",
      "----Batch 7: Shape (1023, 4)----\n",
      "    source   target  time  is_train\n",
      "0  5242882  4194363     0         1\n",
      "----Batch 8: Shape (1035, 4)----\n",
      "    source    target  time  is_train\n",
      "0  3145732  12582928     0         1\n",
      "----Batch 9: Shape (1088, 4)----\n",
      "     source   target  time  is_train\n",
      "0  10485766  2097194     0         0\n",
      "CPU times: user 27.7 ms, sys: 3.58 ms, total: 31.2 ms\n",
      "Wall time: 106 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i, batch in enumerate(edge_loader):\n",
    "    print(\"----Batch {}: Shape {}----\".format(i, batch.shape))\n",
    "    print(batch.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea8f426-9ad8-4219-abb5-c364f04862e8",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### For heterogeneous graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62e3583",
   "metadata": {},
   "source": [
    "Since `Cora` is a homogeneous graph, we will connect to a different graph to demostrate the use case of heterogeneous graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10097615",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = TigerGraphConnection(\n",
    "    host=\"http://127.0.0.1\", # Change the address to your database server's\n",
    "    graphname=\"hetero\",\n",
    "    username=\"tigergraph\",\n",
    "    password=\"tigergraph\",\n",
    "    gsqlSecret=\"\" # secret instead of user/pass is required for TG cloud DBs created after 7/5/2022  \n",
    ")\n",
    "\n",
    "# Uncomment below to get and set token if token authentication is enabled. \n",
    "#conn.getToken(<secret>) # <secret> is your user secret. See https://docs.tigergraph.com/tigergraph-server/current/user-access/managing-credentials#_secrets for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33eb835f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Graph hetero\n",
      "Vertex Types:\n",
      "- VERTEX v0(PRIMARY_ID id INT, x LIST<DOUBLE>, y INT, train_mask BOOL, val_mask BOOL, test_mask BOOL) WITH STATS=\"OUTDEGREE_BY_EDGETYPE\", PRIMARY_ID_AS_ATTRIBUTE=\"true\"\n",
      "- VERTEX v1(PRIMARY_ID id INT, x LIST<DOUBLE>, train_mask BOOL, val_mask BOOL, test_mask BOOL) WITH STATS=\"OUTDEGREE_BY_EDGETYPE\", PRIMARY_ID_AS_ATTRIBUTE=\"true\"\n",
      "- VERTEX v2(PRIMARY_ID id INT, x LIST<DOUBLE>, train_mask BOOL, val_mask BOOL, test_mask BOOL) WITH STATS=\"OUTDEGREE_BY_EDGETYPE\", PRIMARY_ID_AS_ATTRIBUTE=\"true\"\n",
      "Edge Types:\n",
      "- DIRECTED EDGE v0v0(FROM v0, TO v0, is_train BOOL, is_val BOOL)\n",
      "- DIRECTED EDGE v1v1(FROM v1, TO v1, is_train BOOL, is_val BOOL)\n",
      "- DIRECTED EDGE v1v2(FROM v1, TO v2, is_train BOOL, is_val BOOL)\n",
      "- DIRECTED EDGE v2v0(FROM v2, TO v0, is_train BOOL, is_val BOOL)\n",
      "- DIRECTED EDGE v2v1(FROM v2, TO v1, is_train BOOL, is_val BOOL)\n",
      "- DIRECTED EDGE v2v2(FROM v2, TO v2, is_train BOOL, is_val BOOL)\n",
      "\n",
      "Graphs:\n",
      "- Graph hetero(v0:v, v1:v, v2:v, v0v0:e, v1v1:e, v1v2:e, v2v0:e, v2v1:e, v2v2:e)\n",
      "Jobs:\n",
      "- CREATE LOADING JOB load_hetero_data FOR GRAPH hetero {\n",
      "DEFINE FILENAME v2v0_csv = \"./v2v0.csv\";\n",
      "DEFINE FILENAME v2v1_csv = \"./v2v1.csv\";\n",
      "DEFINE FILENAME v2v2_csv = \"./v2v2.csv\";\n",
      "DEFINE FILENAME v1_csv = \"./v1.csv\";\n",
      "DEFINE FILENAME v0v0_csv = \"./v0v0.csv\";\n",
      "DEFINE FILENAME v2_csv = \"./v2.csv\";\n",
      "DEFINE FILENAME v1v1_csv = \"./v1v1.csv\";\n",
      "DEFINE FILENAME v1v2_csv = \"./v1v2.csv\";\n",
      "DEFINE FILENAME v0_csv = \"./v0.csv\";\n",
      "LOAD v0_csv TO VERTEX v0 VALUES($\"id\", SPLIT($\"x\", \" \"), $\"y\", _, _, _) USING SEPARATOR=\",\", HEADER=\"true\", EOL=\"\\n\";\n",
      "LOAD v1_csv TO VERTEX v1 VALUES($\"id\", SPLIT($\"x\", \" \"), _, _, _) USING SEPARATOR=\",\", HEADER=\"true\", EOL=\"\\n\";\n",
      "LOAD v2_csv TO VERTEX v2 VALUES($\"id\", SPLIT($\"x\", \" \"), _, _, _) USING SEPARATOR=\",\", HEADER=\"true\", EOL=\"\\n\";\n",
      "LOAD v0v0_csv TO EDGE v0v0 VALUES($\"source\", $\"target\", _, _) USING SEPARATOR=\",\", HEADER=\"true\", EOL=\"\\n\";\n",
      "LOAD v1v1_csv TO EDGE v1v1 VALUES($\"source\", $\"target\", _, _) USING SEPARATOR=\",\", HEADER=\"true\", EOL=\"\\n\";\n",
      "LOAD v1v2_csv TO EDGE v1v2 VALUES($\"source\", $\"target\", _, _) USING SEPARATOR=\",\", HEADER=\"true\", EOL=\"\\n\";\n",
      "LOAD v2v0_csv TO EDGE v2v0 VALUES($\"source\", $\"target\", _, _) USING SEPARATOR=\",\", HEADER=\"true\", EOL=\"\\n\";\n",
      "LOAD v2v1_csv TO EDGE v2v1 VALUES($\"source\", $\"target\", _, _) USING SEPARATOR=\",\", HEADER=\"true\", EOL=\"\\n\";\n",
      "LOAD v2v2_csv TO EDGE v2v2 VALUES($\"source\", $\"target\", _, _) USING SEPARATOR=\",\", HEADER=\"true\", EOL=\"\\n\";\n",
      "}\n",
      "\n",
      "- CREATE SCHEMA_CHANGE JOB hetero_job FOR GRAPH hetero {\n",
      "ADD VERTEX v0(PRIMARY_ID id INT, x LIST<DOUBLE>, y INT, train_mask BOOL, val_mask BOOL, test_mask BOOL) WITH STATS=\"OUTDEGREE_BY_EDGETYPE\", PRIMARY_ID_AS_ATTRIBUTE=\"true\";\n",
      "ADD VERTEX v1(PRIMARY_ID id INT, x LIST<DOUBLE>, train_mask BOOL, val_mask BOOL, test_mask BOOL) WITH STATS=\"OUTDEGREE_BY_EDGETYPE\", PRIMARY_ID_AS_ATTRIBUTE=\"true\";\n",
      "ADD VERTEX v2(PRIMARY_ID id INT, x LIST<DOUBLE>, train_mask BOOL, val_mask BOOL, test_mask BOOL) WITH STATS=\"OUTDEGREE_BY_EDGETYPE\", PRIMARY_ID_AS_ATTRIBUTE=\"true\";\n",
      "ADD DIRECTED EDGE v0v0(FROM v0, TO v0, is_train BOOL, is_val BOOL);\n",
      "ADD DIRECTED EDGE v1v1(FROM v1, TO v1, is_train BOOL, is_val BOOL);\n",
      "ADD DIRECTED EDGE v1v2(FROM v1, TO v2, is_train BOOL, is_val BOOL);\n",
      "ADD DIRECTED EDGE v2v0(FROM v2, TO v0, is_train BOOL, is_val BOOL);\n",
      "ADD DIRECTED EDGE v2v1(FROM v2, TO v1, is_train BOOL, is_val BOOL);\n",
      "ADD DIRECTED EDGE v2v2(FROM v2, TO v2, is_train BOOL, is_val BOOL);\n",
      "}\n",
      "\n",
      "Queries:\n",
      "- edge_nei_loader_x_y_train_mask_val_mask_test_mask_is_train(int num_batches, int num_neighbors, int num_hops, bool shuffle, string filter_by, set<string> v_types, set<string> e_types, set<string> seed_types, string kafka_address, string kafka_topic, string security_protocol, string sasl_mechanism, string sasl_username, string sasl_password, string ssl_ca_location) (installed v2)\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(conn.gsql(\"ls\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6671e3d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing and optimizing queries. It might take a minute if this is the first time you use this loader.\n",
      "Query installation finished.\n",
      "CPU times: user 27.8 ms, sys: 4.36 ms, total: 32.1 ms\n",
      "Wall time: 32.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "loader = conn.gds.edgeLoader(\n",
    "    attributes={\"v0v0\": [\"is_train\", \"is_val\"],\n",
    "                \"v2v0\": [\"is_train\", \"is_val\"]},\n",
    "    batch_size=200,\n",
    "    shuffle=False,\n",
    "    filter_by=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72e0a75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Batch 0----\n",
      "Edge type: v0v0\n",
      "      source     target is_train is_val\n",
      "0  137363456  136314881        0      0\n",
      "Edge type: v2v0\n",
      "      source     target is_train is_val\n",
      "0  201326594  149946369        0      0\n",
      "----Batch 1----\n",
      "Edge type: v0v0\n",
      "      source     target is_train is_val\n",
      "0  135266305  134217729        0      0\n",
      "Edge type: v2v0\n",
      "      source     target is_train is_val\n",
      "0  204472321  134217729        0      0\n",
      "----Batch 2----\n",
      "Edge type: v0v0\n",
      "      source     target is_train is_val\n",
      "0  135266304  147849218        0      0\n",
      "Edge type: v2v0\n",
      "      source     target is_train is_val\n",
      "0  206569473  158334976        0      0\n",
      "----Batch 3----\n",
      "Edge type: v0v0\n",
      "      source     target is_train is_val\n",
      "0  134217728  136314884        0      0\n",
      "Edge type: v2v0\n",
      "      source     target is_train is_val\n",
      "0  202375169  137363460        0      0\n",
      "----Batch 4----\n",
      "Edge type: v0v0\n",
      "      source     target is_train is_val\n",
      "0  157286401  154140672        0      0\n",
      "Edge type: v2v0\n",
      "      source     target is_train is_val\n",
      "0  201326593  139460610        0      0\n",
      "----Batch 5----\n",
      "Edge type: v0v0\n",
      "      source     target is_train is_val\n",
      "0  161480704  165675008        0      0\n",
      "Edge type: v2v0\n",
      "      source     target is_train is_val\n",
      "0  202375170  137363456        0      0\n",
      "----Batch 6----\n",
      "Edge type: v0v0\n",
      "      source     target is_train is_val\n",
      "0  142606337  134217729        0      0\n",
      "Edge type: v2v0\n",
      "      source     target is_train is_val\n",
      "0  205520898  154140672        0      0\n",
      "----Batch 7----\n",
      "Edge type: v0v0\n",
      "      source     target is_train is_val\n",
      "0  150994945  142606338        0      0\n",
      "Edge type: v2v0\n",
      "      source     target is_train is_val\n",
      "0  202375168  137363458        0      0\n",
      "----Batch 8----\n",
      "Edge type: v0v0\n",
      "      source     target is_train is_val\n",
      "0  165675009  134217731        0      0\n",
      "Edge type: v2v0\n",
      "      source     target is_train is_val\n",
      "0  206569473  147849217        0      0\n",
      "CPU times: user 40.9 ms, sys: 1.36 ms, total: 42.2 ms\n",
      "Wall time: 66.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i, batch in enumerate(loader):\n",
    "    print(\"----Batch {}----\".format(i))\n",
    "    for j in batch:\n",
    "        print(\"Edge type:\", j)\n",
    "        print(batch[j].head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4accd893",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Streaming through Kafka\n",
    "\n",
    "**Note**: Kafka streaming function is only available for the Enterprise Edition. You need to activate the Enterprise Edition to use it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e9dbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = TigerGraphConnection(\n",
    "    host=\"http://127.0.0.1\", # Change the address to your database server's\n",
    "    graphname=\"Cora\",\n",
    "    username=\"tigergraph\",\n",
    "    password=\"tigergraph\",\n",
    "    gsqlSecret=\"\" # secret instead of user/pass is required for TG cloud DBs created after 7/5/2022  \n",
    ")\n",
    "\n",
    "# Uncomment below to get and set token if token authentication is enabled. \n",
    "#conn.getToken(<secret>) # <secret> is your user secret. See https://docs.tigergraph.com/tigergraph-server/current/user-access/managing-credentials#_secrets for details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc52f789-c019-4518-b77b-bf4a13b236ed",
   "metadata": {},
   "source": [
    "#### Configure Kafka\n",
    "Set up Kafka here. Once configured, the settings will be shared with all newly created data loaders and no need to set up Kafka for each loader. Please see official [doc](https://docs.tigergraph.com/pytigergraph/current/gds/gds#_configurekafka) for detailed settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0361d3fb-9755-44c4-8088-2cdb2bd0f710",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.gds.configureKafka(\n",
    "    kafka_address=\"127.0.0.1:9092\",\n",
    "    kafka_security_protocol=\"SASL_PLAINTEXT\",\n",
    "    kafka_sasl_mechanism=\"PLAIN\",\n",
    "    kafka_sasl_plain_username=\"your username\",\n",
    "    kafka_sasl_plain_password=\"your password\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e2cac4-00c7-46c4-99d0-a3ac85055bd4",
   "metadata": {},
   "source": [
    "#### Get batches of edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aff1ee73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing and optimizing queries. It might take a minute if this is the first time you use this loader.\n",
      "Query installation finished.\n",
      "CPU times: user 160 ms, sys: 34.8 ms, total: 195 ms\n",
      "Wall time: 1min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "edge_loader = conn.gds.edgeLoader(\n",
    "    num_batches=10,\n",
    "    attributes=[\"time\", \"is_train\"],\n",
    "    shuffle=True,\n",
    "    filter_by=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f379ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i, batch in enumerate(edge_loader):\n",
    "    print(\"----Batch {}: Shape {}----\".format(i, batch.shape))\n",
    "    print(batch.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2eb36ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-9.m81",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-9:m81"
  },
  "interpreter": {
   "hash": "96daeecb52bbbb8e3aef04d2f9c6a1e01f271d07cea30059f3c558ef00b717d2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc-autonumbering": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
