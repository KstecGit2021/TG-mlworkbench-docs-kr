{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31a41fec-c7f0-4752-b57a-efb428327343",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d51c63-ed05-43d4-9e02-7d13763b5011",
   "metadata": {},
   "source": [
    "This notebook demonstrates the use of edge loader in `pyTigerGraph`. The job of a data loader is to pull data from the TigerGraph database. Currently, the following data loaders are provided:\n",
    "* EdgeLoader, which returns batches of edges.\n",
    "* VertexLoader, which returns batches of vertices.\n",
    "* GraphLoader, which returns randomly sampled (probably disconnected) subgraphs in pandas `dataframe`, `PyG` or `DGL` format.\n",
    "* NeighborLoader, which returns subgraphs using neighbor sampling in `dataframe`, `PyG` or `DGL` format.\n",
    "\n",
    "Every data loader above can either get all the batches as a HTTP response (default) or stream every batch through Kafka. The former mechanism is good for testing with small graphs and it is fast, but it subjects to a data size limit of 2GB. For large graphs, the HTTP channel will likely fail due to size limit and network connectivity issues. Streaming via Kafka is offered for data robustness and scalability. Also, Kafka excels at multi-consumer use cases, and it is efficient for model search or hyperparameter tuning when there are multiiple consumers of the same data. \n",
    "\n",
    "The data loaders support both homogeneous and heterogenous graphs. By default, they load from all vertex and edge types and treat the graph as a homogeneous graph. But they also allow users to specify what vertex and edge types to load from and what attributes to load from each type. This way users will get heterogeneous graph outputs.\n",
    "\n",
    "Note: For the data loaders to work, a few UDFs (User Defined Functions) have to be installed into the TigerGraph database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9243a4-69ae-4a04-ab82-dc6d393e0cb7",
   "metadata": {},
   "source": [
    "### Connection to Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff08e15-5d93-4f30-8a9d-6b101b1604e4",
   "metadata": {},
   "source": [
    "The `TigerGraphConnection` class represents a connection to the TigerGraph database. Under the hood, it stores the necessary information to communicate with the database. It is able to perform quite a few database tasks. Please see its documentation for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b94e2237-5050-4c58-91de-c86b804d19f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyTigerGraph import TigerGraphConnection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2c4b1e8-a0e2-4026-9bb1-218cdc7ca4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = TigerGraphConnection(\n",
    "    host=\"http://127.0.0.1\", # Change the address to your database server's\n",
    "    graphname=\"Cora\",\n",
    "    username=\"tigergraph\",\n",
    "    password=\"tigergraph\",\n",
    "    useCert=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1dd0252-a5e5-47ee-acce-b843571c78cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Paper': 2708}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of vertices for every vertex type\n",
    "conn.getVertexCount('*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "318f1998-1179-4ae2-9f1b-d1b032076c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cite': 10556}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of edges for every type\n",
    "conn.getEdgeCount()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54f29ef-6b65-4999-9363-f9dfde5e478c",
   "metadata": {},
   "source": [
    "### Edge Loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9141a8d2-2a4d-4ced-b4ab-17b5e7604994",
   "metadata": {},
   "source": [
    "EdgeLoader pulls batches of edges from database. Specifically, it divides edges into `num_batches` and returns each batch separately. The boolean attribute provided to `filter_by` indicates which edges are included. If you need random batches, set `shuffle` to True.\n",
    "\n",
    "**Note**: For the first time you initialize the loader on a graph in TigerGraph,\n",
    "the initialization might take a minute as it installs the corresponding\n",
    "query to the database and optimizes it. However, the query installation only\n",
    "needs to be done once, so it will take no time when you initialize the loader\n",
    "on the same TG graph again.\n",
    "\n",
    "There are two ways to use the data loader. See\n",
    "[here](https://github.com/TigerGraph-DevLabs/mlworkbench-docs/blob/main/tutorials/basics/2_dataloaders.ipynb) for examples.\n",
    "* First, it can be used as an iterable, which means you can loop through it to get every batch of data. If you load all edges at once (`num_batches=1`), there will be only one batch (of all the edges) in the iterator.\n",
    "* Second, you can access the `data` property of the class directly. If there is only one batch of data to load, it will give you the batch directly instead of an iterator, which might make more sense in that case. If there are multiple batches of data to load, it will return the loader again.\n",
    "\n",
    "Args:\n",
    "* attributes (list or dict, optional):\n",
    "        Edge attributes to be included. If it is a list, then the attributes\n",
    "        in the list from all edge types will be selected. An error will be thrown if\n",
    "        certain attribute doesn't exist in all edge types. If it is a dict, keys of the \n",
    "        dict are edge types to be selected, and values are lists of attributes to be \n",
    "        selected for each edge type. Defaults to None.\n",
    "* batch_size (int, optional):  \n",
    "        Number of edges in each batch.  \n",
    "        Defaults to None.  \n",
    "* num_batches (int, optional):  \n",
    "        Number of batches to split the edges.  \n",
    "        Defaults to 1.  \n",
    "* shuffle (bool, optional):  \n",
    "        Whether to shuffle the edges before loading data.  \n",
    "        Defaults to False.  \n",
    "* filter_by (str, optional):\n",
    "        A boolean attribute used to indicate which edges are included. Defaults to None.\n",
    "* output_format (str, optional):\n",
    "        Format of the output data of the loader. Only\n",
    "        \"dataframe\" is supported. Defaults to \"dataframe\".\n",
    "* loader_id (str, optional):\n",
    "        An identifier of the loader which can be any string. It is\n",
    "        also used as the Kafka topic name. If `None`, a random string will be generated\n",
    "        for it. Defaults to None.\n",
    "* buffer_size (int, optional):\n",
    "        Number of data batches to prefetch and store in memory. Defaults to 4.\n",
    "* kafka_address (str, optional):\n",
    "        Address of the kafka broker. Defaults to None.\n",
    "* kafka_max_msg_size (int, optional):\n",
    "        Maximum size of a Kafka message in bytes.\n",
    "        Defaults to 104857600.\n",
    "* kafka_num_partitions (int, optional):\n",
    "        Number of partitions for the topic created by this loader.\n",
    "        Defaults to 1.\n",
    "* kafka_replica_factor (int, optional):\n",
    "        Number of replications for the topic created by this\n",
    "        loader. Defaults to 1.\n",
    "* kafka_retention_ms (int, optional):\n",
    "        Retention time for messages in the topic created by this\n",
    "        loader in milliseconds. Defaults to 60000.\n",
    "* kafka_auto_del_topic (bool, optional):\n",
    "        Whether to delete the Kafka topic once the\n",
    "        loader finishes pulling data. Defaults to True.\n",
    "* kafka_address_consumer (str, optional):\n",
    "        Address of the kafka broker that a consumer\n",
    "        should use. Defaults to be the same as `kafkaAddress`.\n",
    "* kafka_address_producer (str, optional):\n",
    "        Address of the kafka broker that a producer\n",
    "        should use. Defaults to be the same as `kafkaAddress`.\n",
    "* timeout (int, optional):\n",
    "        Timeout value for GSQL queries, in ms. Defaults to 300000."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853a985e-2686-496a-8d5b-7f413ebf435a",
   "metadata": {},
   "source": [
    "#### Load all edges at once directly to local. Default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f03830f8-07c9-4d94-b7bd-5489ec7104cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing and optimizing queries. It might take a minute if this is the first time you use this loader.\n",
      "Query installation finished.\n",
      "CPU times: user 217 ms, sys: 38.5 ms, total: 255 ms\n",
      "Wall time: 37.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "edge_loader = conn.gds.edgeLoader(\n",
    "    num_batches=1,\n",
    "    attributes=[\"time\", \"is_train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ef47555-b7b3-4db4-abd6-a9f17f1538f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.4 ms, sys: 4.09 ms, total: 13.5 ms\n",
      "Wall time: 32.9 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10556, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Get the only batch of data via the `data` property\n",
    "data = edge_loader.data\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a75e404-ed20-47dd-830d-8eea8c9e82d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>time</th>\n",
       "      <th>is_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8388608</td>\n",
       "      <td>1048600</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8388608</td>\n",
       "      <td>12582912</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8388608</td>\n",
       "      <td>13631492</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8388608</td>\n",
       "      <td>31457280</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8388609</td>\n",
       "      <td>22020127</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    source    target  time  is_train\n",
       "0  8388608   1048600     0         1\n",
       "1  8388608  12582912     0         1\n",
       "2  8388608  13631492     0         1\n",
       "3  8388608  31457280     0         1\n",
       "4  8388609  22020127     0         1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad44dea5-d5ba-495d-9ca5-2f968f0c8ae5",
   "metadata": {},
   "source": [
    "#### Get batches of edges through http"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecea0bdb-f2d2-4efe-b7cf-e46493f76edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.92 ms, sys: 952 µs, total: 4.87 ms\n",
      "Wall time: 4.98 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "edge_loader = conn.gds.edgeLoader(\n",
    "    num_batches=10,\n",
    "    attributes=[\"time\", \"is_train\"],\n",
    "    shuffle=True,\n",
    "    filter_by=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87ae37fd-f451-48de-ae02-375d10d18fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Batch 0: Shape (1129, 4)----\n",
      "    source    target  time  is_train\n",
      "0  3145728  22020185     0         1\n",
      "----Batch 1: Shape (1002, 4)----\n",
      "    source    target  time  is_train\n",
      "0  1048577  20971586     0         1\n",
      "----Batch 2: Shape (1124, 4)----\n",
      "   source   target  time  is_train\n",
      "0       4  9437199     0         1\n",
      "----Batch 3: Shape (1071, 4)----\n",
      "     source    target  time  is_train\n",
      "0  11534340  32505859     0         1\n",
      "----Batch 4: Shape (978, 4)----\n",
      "     source    target  time  is_train\n",
      "0  11534341  16777293     0         1\n",
      "----Batch 5: Shape (1149, 4)----\n",
      "    source   target  time  is_train\n",
      "0  5242882  2097158     0         1\n",
      "----Batch 6: Shape (1013, 4)----\n",
      "    source    target  time  is_train\n",
      "0  4194305  23068698     0         1\n",
      "----Batch 7: Shape (1037, 4)----\n",
      "    source   target  time  is_train\n",
      "0  7340035  4194337     0         0\n",
      "----Batch 8: Shape (1067, 4)----\n",
      "   source   target  time  is_train\n",
      "0       3  1048595     0         1\n",
      "----Batch 9: Shape (986, 4)----\n",
      "    source    target  time  is_train\n",
      "0  9437185  13631508     0         1\n",
      "CPU times: user 27.5 ms, sys: 3.51 ms, total: 31 ms\n",
      "Wall time: 117 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i, batch in enumerate(edge_loader):\n",
    "    print(\"----Batch {}: Shape {}----\".format(i, batch.shape))\n",
    "    print(batch.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4accd893",
   "metadata": {},
   "source": [
    "#### Stream batches of edges through Kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aff1ee73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:kafka.coordinator.consumer:group_id is None: disabling auto-commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing and optimizing queries. It might take a minute if this is the first time you use this loader.\n",
      "Query installation finished.\n",
      "CPU times: user 45 ms, sys: 5.45 ms, total: 50.4 ms\n",
      "Wall time: 25.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "edge_loader = conn.gds.edgeLoader(\n",
    "    num_batches=10,\n",
    "    attributes=[\"time\", \"is_train\"],\n",
    "    shuffle=True,\n",
    "    filter_by=None,\n",
    "    kafka_address=\"127.0.0.1:9092\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4f379ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Batch 0: Shape (995, 4)----\n",
      "   source    target  time  is_train\n",
      "0       1  13631492     0         1\n",
      "----Batch 1: Shape (1118, 4)----\n",
      "    source   target  time  is_train\n",
      "0  8388608  1048600     0         1\n",
      "----Batch 2: Shape (1130, 4)----\n",
      "     source   target  time  is_train\n",
      "0  11534337  7340055     0         1\n",
      "----Batch 3: Shape (1069, 4)----\n",
      "    source    target  time  is_train\n",
      "0  5242889  18874424     0         1\n",
      "----Batch 4: Shape (1056, 4)----\n",
      "    source    target  time  is_train\n",
      "0  3145728  16777284     0         1\n",
      "----Batch 5: Shape (1037, 4)----\n",
      "    source   target  time  is_train\n",
      "0  1048578  2097165     0         1\n",
      "----Batch 6: Shape (1026, 4)----\n",
      "     source    target  time  is_train\n",
      "0  13631490  17825817     0         0\n",
      "----Batch 7: Shape (1048, 4)----\n",
      "    source   target  time  is_train\n",
      "0  4194304  9437199     0         1\n",
      "----Batch 8: Shape (1083, 4)----\n",
      "     source    target  time  is_train\n",
      "0  25165829  31457319     0         0\n",
      "----Batch 9: Shape (994, 4)----\n",
      "   source   target  time  is_train\n",
      "0       0  6291456     0         1\n",
      "CPU times: user 49.1 ms, sys: 11.4 ms, total: 60.6 ms\n",
      "Wall time: 1.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i, batch in enumerate(edge_loader):\n",
    "    print(\"----Batch {}: Shape {}----\".format(i, batch.shape))\n",
    "    print(batch.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea8f426-9ad8-4219-abb5-c364f04862e8",
   "metadata": {},
   "source": [
    "#### For heterogeneous graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62e3583",
   "metadata": {},
   "source": [
    "Since `Cora` is a homogeneous graph, we will connect to a different graph to demostrate the use case of heterogeneous graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10097615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 87 µs, sys: 14 µs, total: 101 µs\n",
      "Wall time: 105 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "conn = TigerGraphConnection(\n",
    "    host=\"http://127.0.0.1\", # Change the address to your database server's\n",
    "    graphname=\"hetero\",\n",
    "    username=\"tigergraph\",\n",
    "    password=\"tigergraph\",\n",
    "    useCert=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33eb835f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Graph hetero\n",
      "Vertex Types:\n",
      "- VERTEX v0(PRIMARY_ID id INT, x LIST<DOUBLE>, y INT, train_mask BOOL, val_mask BOOL, test_mask BOOL) WITH STATS=\"OUTDEGREE_BY_EDGETYPE\", PRIMARY_ID_AS_ATTRIBUTE=\"true\"\n",
      "- VERTEX v1(PRIMARY_ID id INT, x LIST<DOUBLE>, train_mask BOOL, val_mask BOOL, test_mask BOOL) WITH STATS=\"OUTDEGREE_BY_EDGETYPE\", PRIMARY_ID_AS_ATTRIBUTE=\"true\"\n",
      "- VERTEX v2(PRIMARY_ID id INT, x LIST<DOUBLE>, train_mask BOOL, val_mask BOOL, test_mask BOOL) WITH STATS=\"OUTDEGREE_BY_EDGETYPE\", PRIMARY_ID_AS_ATTRIBUTE=\"true\"\n",
      "Edge Types:\n",
      "- DIRECTED EDGE v0v0(FROM v0, TO v0, is_train BOOL, is_val BOOL)\n",
      "- DIRECTED EDGE v1v1(FROM v1, TO v1, is_train BOOL, is_val BOOL)\n",
      "- DIRECTED EDGE v1v2(FROM v1, TO v2, is_train BOOL, is_val BOOL)\n",
      "- DIRECTED EDGE v2v0(FROM v2, TO v0, is_train BOOL, is_val BOOL)\n",
      "- DIRECTED EDGE v2v1(FROM v2, TO v1, is_train BOOL, is_val BOOL)\n",
      "- DIRECTED EDGE v2v2(FROM v2, TO v2, is_train BOOL, is_val BOOL)\n",
      "\n",
      "Graphs:\n",
      "- Graph hetero(v0:v, v1:v, v2:v, v0v0:e, v1v1:e, v1v2:e, v2v0:e, v2v1:e, v2v2:e)\n",
      "Jobs:\n",
      "- CREATE LOADING JOB load_hetero_data FOR GRAPH hetero {\n",
      "DEFINE FILENAME v2v0_csv = \"./v2v0.csv\";\n",
      "DEFINE FILENAME v2v1_csv = \"./v2v1.csv\";\n",
      "DEFINE FILENAME v2v2_csv = \"./v2v2.csv\";\n",
      "DEFINE FILENAME v1_csv = \"./v1.csv\";\n",
      "DEFINE FILENAME v0v0_csv = \"./v0v0.csv\";\n",
      "DEFINE FILENAME v2_csv = \"./v2.csv\";\n",
      "DEFINE FILENAME v1v1_csv = \"./v1v1.csv\";\n",
      "DEFINE FILENAME v1v2_csv = \"./v1v2.csv\";\n",
      "DEFINE FILENAME v0_csv = \"./v0.csv\";\n",
      "LOAD v0_csv TO VERTEX v0 VALUES($\"id\", SPLIT($\"x\", \" \"), $\"y\", _, _, _) USING SEPARATOR=\",\", HEADER=\"true\", EOL=\"\\n\";\n",
      "LOAD v1_csv TO VERTEX v1 VALUES($\"id\", SPLIT($\"x\", \" \"), _, _, _) USING SEPARATOR=\",\", HEADER=\"true\", EOL=\"\\n\";\n",
      "LOAD v2_csv TO VERTEX v2 VALUES($\"id\", SPLIT($\"x\", \" \"), _, _, _) USING SEPARATOR=\",\", HEADER=\"true\", EOL=\"\\n\";\n",
      "LOAD v0v0_csv TO EDGE v0v0 VALUES($\"source\", $\"target\", _, _) USING SEPARATOR=\",\", HEADER=\"true\", EOL=\"\\n\";\n",
      "LOAD v1v1_csv TO EDGE v1v1 VALUES($\"source\", $\"target\", _, _) USING SEPARATOR=\",\", HEADER=\"true\", EOL=\"\\n\";\n",
      "LOAD v1v2_csv TO EDGE v1v2 VALUES($\"source\", $\"target\", _, _) USING SEPARATOR=\",\", HEADER=\"true\", EOL=\"\\n\";\n",
      "LOAD v2v0_csv TO EDGE v2v0 VALUES($\"source\", $\"target\", _, _) USING SEPARATOR=\",\", HEADER=\"true\", EOL=\"\\n\";\n",
      "LOAD v2v1_csv TO EDGE v2v1 VALUES($\"source\", $\"target\", _, _) USING SEPARATOR=\",\", HEADER=\"true\", EOL=\"\\n\";\n",
      "LOAD v2v2_csv TO EDGE v2v2 VALUES($\"source\", $\"target\", _, _) USING SEPARATOR=\",\", HEADER=\"true\", EOL=\"\\n\";\n",
      "}\n",
      "\n",
      "Queries:\n",
      "- edge_loader_(int num_batches, bool shuffle, string filter_by, set<string> e_types, string kafka_address, string kafka_topic) (installed v2)\n",
      "- edge_loader_is_train_is_val(int num_batches, bool shuffle, string filter_by, set<string> e_types, string kafka_address, string kafka_topic) (installed v2)\n",
      "- graph_loader_x_y_train_mask_val_mask_test_mask(int num_batches, bool shuffle, string filter_by, set<string> v_types, set<string> e_types, string kafka_address, string kafka_topic) (installed v2)\n",
      "- graph_loader_x_y_train_mask_val_mask_test_mask_is_train_is_val(int num_batches, bool shuffle, string filter_by, set<string> v_types, set<string> e_types, string kafka_address, string kafka_topic) (installed v2)\n",
      "- neighbor_hloader_test_mask_x_train_mask_val_mask_y(set<vertex> input_vertices, int num_batches, int num_neighbors, int num_hops, bool shuffle, string filter_by, set<string> v_types, set<string> e_types) (installed v2)\n",
      "- neighbor_hloader_test_mask_y_x_val_mask_train_mask(set<vertex> input_vertices, int num_batches, int num_neighbors, int num_hops, bool shuffle, string filter_by, set<string> v_types, set<string> e_types) (installed v2)\n",
      "- neighbor_hloader_train_mask_y_test_mask_x_val_mask(set<vertex> input_vertices, int num_batches, int num_neighbors, int num_hops, bool shuffle, string filter_by, set<string> v_types, set<string> e_types) (installed v2)\n",
      "- neighbor_hloader_x_y_test_mask_train_mask_val_mask(set<vertex> input_vertices, int num_batches, int num_neighbors, int num_hops, bool shuffle, string filter_by, set<string> v_types, set<string> e_types) (installed v2)\n",
      "- neighbor_hloader_x_y_train_mask_val_mask_test_mask(set<vertex> input_vertices, int num_batches, int num_neighbors, int num_hops, bool shuffle, string filter_by, set<string> v_types, set<string> e_types) (installed v2)\n",
      "- neighbor_loader_x_y_train_mask_val_mask_test_mask(set<vertex> input_vertices, int num_batches, int num_neighbors, int num_hops, bool shuffle, string filter_by, set<string> v_types, set<string> e_types, string kafka_address, string kafka_topic) (installed v2)\n",
      "- vertex_loader_x_y(set<vertex> input_vertices, int num_batches, bool shuffle, string filter_by, set<string> v_types, string kafka_address, string kafka_topic) (installed v2)\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(conn.gsql(\"ls\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6671e3d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.3 ms, sys: 7.42 ms, total: 42.8 ms\n",
      "Wall time: 369 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "loader = conn.gds.edgeLoader(\n",
    "    attributes={\"v0v0\": [\"is_train\", \"is_val\"],\n",
    "                \"v2v0\": [\"is_train\", \"is_val\"]},\n",
    "    batch_size=200,\n",
    "    shuffle=False,\n",
    "    filter_by=None,\n",
    "    loader_id=None,\n",
    "    buffer_size=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72e0a75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Batch 0----\n",
      "Edge type: v0v0\n",
      "     source    target is_train is_val\n",
      "0  69206018  77594624        0      0\n",
      "Edge type: v2v0\n",
      "      source    target is_train is_val\n",
      "0  138412034  72351746        0      0\n",
      "----Batch 1----\n",
      "Edge type: v0v0\n",
      "     source    target is_train is_val\n",
      "0  68157440  94371841        0      0\n",
      "Edge type: v2v0\n",
      "      source    target is_train is_val\n",
      "0  139460608  67108869        0      0\n",
      "----Batch 2----\n",
      "Edge type: v2v0\n",
      "      source    target is_train is_val\n",
      "0  137363457  68157440        0      0\n",
      "Edge type: v0v0\n",
      "     source    target is_train is_val\n",
      "0  67108866  75497473        0      0\n",
      "----Batch 3----\n",
      "Edge type: v0v0\n",
      "     source    target is_train is_val\n",
      "0  75497474  87031809        0      0\n",
      "Edge type: v2v0\n",
      "      source    target is_train is_val\n",
      "0  108003329  80740352        0      0\n",
      "----Batch 4----\n",
      "Edge type: v0v0\n",
      "     source    target is_train is_val\n",
      "0  76546048  71303169        0      0\n",
      "Edge type: v2v0\n",
      "      source    target is_train is_val\n",
      "0  134217730  92274688        0      0\n",
      "----Batch 5----\n",
      "Edge type: v0v0\n",
      "     source    target is_train is_val\n",
      "0  71303169  67108865        0      0\n",
      "Edge type: v2v0\n",
      "      source    target is_train is_val\n",
      "0  134217732  95420416        0      0\n",
      "----Batch 6----\n",
      "Edge type: v0v0\n",
      "     source    target is_train is_val\n",
      "0  77594624  67108865        0      0\n",
      "Edge type: v2v0\n",
      "      source    target is_train is_val\n",
      "0  150994946  80740356        0      0\n",
      "----Batch 7----\n",
      "Edge type: v0v0\n",
      "     source    target is_train is_val\n",
      "0  97517569  92274688        0      0\n",
      "Edge type: v2v0\n",
      "      source    target is_train is_val\n",
      "0  134217730  67108866        0      0\n",
      "----Batch 8----\n",
      "Edge type: v2v0\n",
      "      source    target is_train is_val\n",
      "0  157286400  70254592        0      0\n",
      "Edge type: v0v0\n",
      "     source    target is_train is_val\n",
      "0  68157441  70254593        0      0\n",
      "CPU times: user 83.4 ms, sys: 4.6 ms, total: 88 ms\n",
      "Wall time: 190 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i, batch in enumerate(loader):\n",
    "    print(\"----Batch {}----\".format(i))\n",
    "    for j in batch:\n",
    "        print(\"Edge type:\", j)\n",
    "        print(batch[j].head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2eb36ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-9.m81",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-9:m81"
  },
  "interpreter": {
   "hash": "96daeecb52bbbb8e3aef04d2f9c6a1e01f271d07cea30059f3c558ef00b717d2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc-autonumbering": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
