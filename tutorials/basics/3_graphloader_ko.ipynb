{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31a41fec-c7f0-4752-b57a-efb428327343",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 데이터 로더(Data Loaders)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d51c63-ed05-43d4-9e02-7d13763b5011",
   "metadata": {},
   "source": [
    "이 노트북은 `pyTigerGraph` 에서 **graph loader** 의 사용을 보여줍니다. 데이터 로더의 역할은 `TigerGraph` 데이터베이스에서 데이터를 가져오는 것입니다. 현재 다음 데이터 로더가 제공됩니다.\n",
    "\n",
    "* EdgeLoader, 간선의 배치(batch)를 반환합니다.\n",
    "* VertexLoader, 정점의 배치(batch)를 반환합니다.\n",
    "* GraphLoader, 무작위로 샘플링된(연결이 끊긴) 하위 그래프(subgraphs)를 pandas의 `dataframe`, `PyG` 또는 `DGL` 형식으로 반환 합니다.\n",
    "* NeighborLoader, 이웃 샘플링을 사용하여 하위 그래프(subgraphs)를 `dataframe`, `PyG` 또는 `DGL`  형식으로 반환 합니다.\n",
    "* EdgeNeighborLoader, 간선들에서 이웃 샘플링을 사용하여 하위 그래프(subgraphs)를 `dataframe`, `PyG` 또는 `DGL` 형식으로 반환 합니다.\n",
    "\n",
    "위의 모든 데이터 로더는 모든 배치를 HTTP 응답(기본값)으로 가져오거나 Kafka를 통해 모든 배치를 스트리밍할 수 있습니다. 전자의 메커니즘은 작은 그래프로 테스트하기에 좋고 빠르지만 데이터 크기 제한이 2GB입니다. 큰 그래프의 경우 크기 제한 및 네트워크 연결 문제로 인해 HTTP 채널이 실패할 수 있습니다. Kafka를 통한 스트리밍은 데이터 견고성과 확장성을 위해 제공됩니다. 또한 Kafka는 다중 소비자(multi-consumer) 사용 사례에 탁월하며 동일한 데이터의 다중 소비자가 있는 경우 모델 검색 또는 하이퍼파라미터 튜닝에 효율적입니다.\n",
    "\n",
    "데이터 로더는 동종 및 이종 그래프를 모두 지원합니다. 기본적으로 모든 정점 및 간선 유형에서 로드하고 그래프를 동종 그래프로 처리합니다. 그러나 사용자가 로드할 정점 및 간선 유형과 각 유형에서 로드할 속성을 지정할 수도 있습니다. 이 방법으로 사용자는 이기종 그래프 출력을 얻을 수 있습니다.\n",
    "\n",
    "**NOTE**: 현재 ML Workbench에서 제공하는 모든 기능을 사용하려면 데이터베이스를 한 번만 활성화(activage)해야 합니다. ML Workbench on Cloud를 사용하는 경우 activator가 포함되며 아래 셀을 실행(먼저 주석 해제)하여 활성화(activage)할 수 있습니다. 다른 버전의 Workbench의 경우 https://act.tigergraphlabs.com 에서 활성기(activator)를 다운로드할 수 있습니다. 자세한 지침은 해당 웹사이트에도 포함되어 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5f4fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아래 주석을 제거하고 필요한 정보를 입력하십시오. 자세한 지침은 https://act.tigergraphlabs.com을 참조하십시오.\n",
    "# !mlwb activate [database address] -u [username] -p [password] -s [secret]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9243a4-69ae-4a04-ab82-dc6d393e0cb7",
   "metadata": {},
   "source": [
    "### 데이터베이스 연결 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff08e15-5d93-4f30-8a9d-6b101b1604e4",
   "metadata": {},
   "source": [
    "이 `TigerGraphConnection` 클래스는 TigerGraph 데이터베이스에 대한 연결을 나타냅니다. 후드 아래에는 데이터베이스와 통신하는 데 필요한 정보가 저장됩니다. 꽤 많은 데이터베이스 작업을 수행할 수 있습니다. 자세한 내용은 해당 [문서](https://docs.tigergraph.com/pytigergraph/current/intro/) 를 참조하십시오.\n",
    "\n",
    "**Note**: 2022년 7월 5일 이후에 생성된 TG 클라우드 DB는 사용자 username/password 대신 Secret가 필요합니다. 그렇지 않으면 비워 둘 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b94e2237-5050-4c58-91de-c86b804d19f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyTigerGraph import TigerGraphConnection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2c4b1e8-a0e2-4026-9bb1-218cdc7ca4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = TigerGraphConnection(\n",
    "    host=\"http://127.0.0.1\", # 데이터베이스 서버의 주소로 변경\n",
    "    graphname=\"Cora\",\n",
    "    username=\"tigergraph\",\n",
    "    password=\"tigergraph\",\n",
    "    gsqlSecret=\"\" # 2022년 7월 5일 이후에 생성된 TG 클라우드 DB에는 user/pass 대신 secret이 필요합니다.  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec12e546",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">아래 셀의 주석을 제거하고 토큰 인증이 활성화된 경우 토큰을 가져오고 설정하기 위해 실행합니다.</span>. \n",
    "* 이것은 tgcloud의 모든 데이터베이스에 필요합니다.\n",
    "* `<secret>`은 사용자 암호입니다. 자세한 내용은 https://docs.tigergraph.com/tigergraph-server/current/user-access/managing-credentials#_secrets 를 참조하세요.\n",
    "* secret을 모르는 경우  `secret=conn.createSecret()`를 사용하여 secret을 만들 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127e0520",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conn.getToken(<secret>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1dd0252-a5e5-47ee-acce-b843571c78cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Paper': 2708}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모든 정점 유형에 대한 정점 수\n",
    "conn.getVertexCount('*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "318f1998-1179-4ae2-9f1b-d1b032076c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cite': 10556}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모든 간선 유형에 대한 간선 수\n",
    "conn.getEdgeCount()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f9e835-5715-4d9e-b19b-ee1f596b8aba",
   "metadata": {},
   "source": [
    "### 그래프 로더(Graph Loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97f834b",
   "metadata": {},
   "source": [
    "`GraphLoader`는 데이터베이스에서 (연결이 끊긴) 하위 그래프를 가져옵니다. 연결된 하위 그래프를 생성하는 NeighborLoader와 달리 이 로더는 해당 에지에 연결된 에지 및 정점의 배치(임의)를 가져옵니다.\n",
    "\n",
    "**Note**: TigerGraph의 그래프에서 로더를 처음 초기화하는 경우 해당 쿼리를 데이터베이스에 설치하고 최적화하므로 초기화에 1분이 걸릴 수 있습니다. 하지만 쿼리 설치는 한 번만 하면 되므로 동일한 TG 그래프에서 다시 로더를 초기화할 때 시간이 걸리지 않습니다.\n",
    "        \n",
    "데이터 로더를 사용하는 방법에는 두 가지가 있습니다. 예시는 [여기](https://github.com/TigerGraph-DevLabs/mlworkbench-docs/blob/main/tutorials/basics/2_dataloaders.ipynb)를 참조하세요.\n",
    "* 첫째, iterable로 사용할 수 있습니다. 즉, 루프를 통해 모든 데이터 배치를 가져올 수 있습니다. 모든 데이터를 한 번에 로드하는 경우(`num_batches=1`), 반복자에는 하나의 배치(모든 데이터 중)만 있습니다.\n",
    "* 둘째, 클래스의 `data` 속성에 직접 접근할 수 있습니다. 로드할 데이터 배치가 하나만 있는 경우 반복자 대신 배치를 직접 제공하므로 이 경우 더 합리적일 수 있습니다. 로드할 데이터 배치가 여러 개인 경우 로더 자체를 반환합니다.\n",
    "\n",
    "인수(Args):\n",
    "* v_in_feats (list or dict, optional):\n",
    "        입력 기능(feature)으로 사용할 정점 속성입니다.\n",
    "        목록인 경우 모든 정점 유형의 목록에 있는 속성이 선택됩니다. \n",
    "        특정 속성이 모든 정점 유형에 존재하지 않으면 오류가 발생합니다. \n",
    "        dict인 경우 dict의 키는 선택할 정점 유형이고 값은 각 정점 유형에 대해 \n",
    "        선택해야 하는 속성의 목록입니다.\n",
    "        숫자 및 부울 속성만 허용됩니다. \n",
    "        속성 유형은 데이터베이스 스키마에서 자동으로 결정됩니다. 기본값은 없음입니다.\n",
    "* v_out_labels(목록 또는 사전, 선택 사항):\n",
    "        예측을 위한 레이블로 사용할 정점 속성입니다.\n",
    "        목록인 경우 모든 정점 유형의 목록에 있는 속성이 선택됩니다. \n",
    "        특정 속성이 모든 정점 유형에 존재하지 않으면 오류가 발생합니다. \n",
    "        dict인 경우 dict의 키는 선택할 정점 유형이고 값은 각 정점 유형에 대해 \n",
    "        선택해야 하는 속성의 목록입니다.\n",
    "        숫자 및 부울 속성만 허용됩니다. 기본값은 없음입니다.\n",
    "* v_extra_feats (list or dict, optional):\n",
    "        학습/테스트 데이터의 지표와 같이 가져올 기타 속성입니다.\n",
    "        목록인 경우 모든 정점 유형의 목록에 있는 속성이 선택됩니다. \n",
    "        특정 속성이 모든 정점 유형에 존재하지 않으면 오류가 발생합니다. \n",
    "        dict인 경우 dict의 키는 선택할 정점 유형이고 값은 각 정점 유형에 대해 \n",
    "        선택해야 하는 속성의 목록입니다.\n",
    "        모든 유형의 속성이 허용됩니다. 기본값은 없음입니다.\n",
    "* e_in_feats (list or dict, optional):\n",
    "        입력 기능(feature)으로 사용할 에지 속성입니다.\n",
    "        목록인 경우 모든 에지 유형의 목록에 있는 속성이 선택됩니다. \n",
    "        특정 속성이 모든 에지 유형에 존재하지 않는 경우 오류가 발생합니다. \n",
    "        dict인 경우 dict의 키는 선택해야 하는 에지 유형이고 값은 에지 유형별로 \n",
    "        선택해야 하는 속성의 목록입니다.\n",
    "        숫자 및 부울 속성만 허용됩니다. \n",
    "        속성 유형은 데이터베이스 스키마에서 자동으로 결정됩니다. 기본값은 없음입니다.\n",
    "* e_out_labels (list or dict, optional):\n",
    "        예측을 위한 레이블로 사용할 에지 속성입니다.\n",
    "        목록인 경우 모든 에지 유형의 목록에 있는 속성이 선택됩니다. \n",
    "        특정 속성이 모든 에지 유형에 존재하지 않는 경우 오류가 발생합니다. \n",
    "        dict인 경우 dict의 키는 선택해야 하는 에지 유형이고 값은 에지 유형별로 \n",
    "        선택해야 하는 속성의 목록입니다.\n",
    "        숫자 및 부울 속성만 허용됩니다. 기본값은 없음입니다.\n",
    "* e_extra_feats (list or dict, optional):\n",
    "        훈련/테스트 데이터의 지표와 같이 얻을 다른 에지 속성.\n",
    "        목록인 경우 모든 에지 유형의 목록에 있는 속성이 선택됩니다. \n",
    "        특정 속성이 모든 에지 유형에 존재하지 않는 경우 오류가 발생합니다. \n",
    "        dict인 경우 dict의 키는 선택해야 하는 에지 유형이고 값은 에지 유형별로 \n",
    "        선택해야 하는 속성의 목록입니다.\n",
    "        모든 유형의 속성이 허용됩니다. 기본값은 없음입니다.\n",
    "* batch_size (int, optional):\n",
    "        각 배치의 정점 수입니다.\n",
    "        기본값은 없음입니다.\n",
    "* num_batches (int, optional):\n",
    "        에지를 분할할 배치 수입니다.\n",
    "        기본값은 1입니다.\n",
    "* shuffle (bool, optional):\n",
    "        로드하기 전에 데이터를 섞을지 여부입니다.\n",
    "        기본값은 False입니다.\n",
    "* filter_by (str, optional):\n",
    "        포함할 수 있는 에지를 나타내는 데 사용되는 부울 속성입니다.\n",
    "        기본값은 없음입니다.\n",
    "* output_format (str, optional):\n",
    "        로더의 출력 데이터 형식입니다.\n",
    "        \"PyG\", \"DGL\" 및 \"dataframe\"만 지원됩니다. 기본값은 \"데이터 프레임\"입니다.\n",
    "* add_self_loop (bool, optional):\n",
    "        그래프에 자체 루프를 추가할지 여부입니다. 기본값은 False입니다.\n",
    "* loader_id (str, optional):\n",
    "        임의의 문자열이 될 수 있는 로더의 식별자입니다. Kafka 주제 이름으로도 사용됩니다. \n",
    "        `None`이면 임의의 문자열이 생성됩니다. 기본값은 없음입니다.\n",
    "* buffer_size (int, optional):\n",
    "        메모리에 프리페치하고 저장할 데이터 배치 수입니다. 기본값은 4입니다.\n",
    "* timeout (int, optional):\n",
    "        GSQL 쿼리에 대한 시간 초과 값(ms)입니다. 기본값은 300000입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23581259-4981-4439-82ff-3ec71f59cb16",
   "metadata": {},
   "source": [
    "#### 전체 그래프를 PyG 그래프로 로컬에 직접 로드 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d5e7d18-b57f-4cb2-b29f-fff2349ca7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing and optimizing queries. It might take a minute if this is the first time you use this loader.\n",
      "Query installation finished.\n",
      "CPU times: user 220 ms, sys: 58.1 ms, total: 278 ms\n",
      "Wall time: 49.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "graph_loader = conn.gds.graphLoader(\n",
    "    num_batches=1,\n",
    "    v_in_feats = [\"x\"],\n",
    "    v_out_labels = [\"y\"],\n",
    "    v_extra_feats = [\"train_mask\", \"val_mask\", \"test_mask\"],\n",
    "    e_in_feats=[\"time\"],\n",
    "    e_out_labels=[],\n",
    "    e_extra_feats=[\"is_train\", \"is_val\"],\n",
    "    output_format = \"PyG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9615d76-8c04-483c-aa1a-87782478520b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.71 s, sys: 176 ms, total: 1.89 s\n",
      "Wall time: 1.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# `data` 속성을 통해 데이터의 유일한 배치를 가져옵니다.\n",
    "data = graph_loader.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5049afd0-403d-4abc-98cd-6dc0ec826586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 10556], edge_feat=[10556], is_train=[10556], is_val=[10556], x=[2708, 1433], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fc6fb4-9e7b-4d7a-8c97-aa5d43b18468",
   "metadata": {},
   "source": [
    "#### http를 통해 하위 그래프(subgraph) 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e375023-ec7d-4afd-b069-6220b91a758f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.08 ms, sys: 1.99 ms, total: 5.07 ms\n",
      "Wall time: 7.76 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "graph_loader = conn.gds.graphLoader(\n",
    "    num_batches=10,\n",
    "    v_in_feats = [\"x\"],\n",
    "    v_out_labels = [\"y\"],\n",
    "    v_extra_feats = [\"train_mask\", \"val_mask\", \"test_mask\"],\n",
    "    e_in_feats=[\"time\"],\n",
    "    e_out_labels=[],\n",
    "    e_extra_feats=[\"is_train\", \"is_val\"],\n",
    "    output_format = \"PyG\",\n",
    "    shuffle=True,\n",
    "    filter_by=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75992748-4d64-4f7d-92f7-fa24f4f1d8f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Batch 0----\n",
      "Data(edge_index=[2, 938], edge_feat=[938], is_train=[938], is_val=[938], x=[954, 1433], y=[954], train_mask=[954], val_mask=[954], test_mask=[954])\n",
      "----Batch 1----\n",
      "Data(edge_index=[2, 1089], edge_feat=[1089], is_train=[1089], is_val=[1089], x=[1260, 1433], y=[1260], train_mask=[1260], val_mask=[1260], test_mask=[1260])\n",
      "----Batch 2----\n",
      "Data(edge_index=[2, 1086], edge_feat=[1086], is_train=[1086], is_val=[1086], x=[1237, 1433], y=[1237], train_mask=[1237], val_mask=[1237], test_mask=[1237])\n",
      "----Batch 3----\n",
      "Data(edge_index=[2, 1062], edge_feat=[1062], is_train=[1062], is_val=[1062], x=[1256, 1433], y=[1256], train_mask=[1256], val_mask=[1256], test_mask=[1256])\n",
      "----Batch 4----\n",
      "Data(edge_index=[2, 1059], edge_feat=[1059], is_train=[1059], is_val=[1059], x=[1149, 1433], y=[1149], train_mask=[1149], val_mask=[1149], test_mask=[1149])\n",
      "----Batch 5----\n",
      "Data(edge_index=[2, 1020], edge_feat=[1020], is_train=[1020], is_val=[1020], x=[997, 1433], y=[997], train_mask=[997], val_mask=[997], test_mask=[997])\n",
      "----Batch 6----\n",
      "Data(edge_index=[2, 1079], edge_feat=[1079], is_train=[1079], is_val=[1079], x=[1228, 1433], y=[1228], train_mask=[1228], val_mask=[1228], test_mask=[1228])\n",
      "----Batch 7----\n",
      "Data(edge_index=[2, 1085], edge_feat=[1085], is_train=[1085], is_val=[1085], x=[1265, 1433], y=[1265], train_mask=[1265], val_mask=[1265], test_mask=[1265])\n",
      "----Batch 8----\n",
      "Data(edge_index=[2, 1100], edge_feat=[1100], is_train=[1100], is_val=[1100], x=[1265, 1433], y=[1265], train_mask=[1265], val_mask=[1265], test_mask=[1265])\n",
      "----Batch 9----\n",
      "Data(edge_index=[2, 1038], edge_feat=[1038], is_train=[1038], is_val=[1038], x=[1141, 1433], y=[1141], train_mask=[1141], val_mask=[1141], test_mask=[1141])\n",
      "CPU times: user 20.2 s, sys: 866 ms, total: 21.1 s\n",
      "Wall time: 3.64 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i, batch in enumerate(graph_loader):\n",
    "    print(\"----Batch {}----\".format(i))\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6213a648",
   "metadata": {},
   "source": [
    "#### 이종(heterogeneous) 그래프의 경우"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8dac11",
   "metadata": {},
   "source": [
    "`Cora`는 동종(homogeneous) 그래프 이므로 다른 그래프에 연결하여 이종(demostrate) 그래프의 사용 사례를 시연합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb2bfb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = TigerGraphConnection(\n",
    "    host=\"http://127.0.0.1\", # 데이터베이스 서버의 주소로 변경\n",
    "    graphname=\"hetero\",\n",
    "    username=\"tigergraph\",\n",
    "    password=\"tigergraph\",\n",
    "    gsqlSecret=\"\" # 2022년 7월 5일 이후에 생성된 TG 클라우드 DB에는 user/pass 대신 secret이 필요합니다.  \n",
    ")\n",
    "\n",
    "# 토큰 인증이 활성화된 경우 토큰을 가져오고 설정하려면 아래 주석을 제거하십시오.\n",
    "#conn.getToken(<secret>) # <secret>은 사용자 암호입니다. 자세한 내용은 https://docs.tigergraph.com/tigergraph-server/current/user-access/managing-credentials#_secrets를 참조하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "223e6cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Graph hetero\n",
      "Vertex Types:\n",
      "- VERTEX v0(PRIMARY_ID id INT, x LIST<DOUBLE>, y INT, train_mask BOOL, val_mask BOOL, test_mask BOOL) WITH STATS=\"OUTDEGREE_BY_EDGETYPE\", PRIMARY_ID_AS_ATTRIBUTE=\"true\"\n",
      "- VERTEX v1(PRIMARY_ID id INT, x LIST<DOUBLE>, train_mask BOOL, val_mask BOOL, test_mask BOOL) WITH STATS=\"OUTDEGREE_BY_EDGETYPE\", PRIMARY_ID_AS_ATTRIBUTE=\"true\"\n",
      "- VERTEX v2(PRIMARY_ID id INT, x LIST<DOUBLE>, train_mask BOOL, val_mask BOOL, test_mask BOOL) WITH STATS=\"OUTDEGREE_BY_EDGETYPE\", PRIMARY_ID_AS_ATTRIBUTE=\"true\"\n",
      "Edge Types:\n",
      "- DIRECTED EDGE v0v0(FROM v0, TO v0, is_train BOOL, is_val BOOL)\n",
      "- DIRECTED EDGE v1v1(FROM v1, TO v1, is_train BOOL, is_val BOOL)\n",
      "- DIRECTED EDGE v1v2(FROM v1, TO v2, is_train BOOL, is_val BOOL)\n",
      "- DIRECTED EDGE v2v0(FROM v2, TO v0, is_train BOOL, is_val BOOL)\n",
      "- DIRECTED EDGE v2v1(FROM v2, TO v1, is_train BOOL, is_val BOOL)\n",
      "- DIRECTED EDGE v2v2(FROM v2, TO v2, is_train BOOL, is_val BOOL)\n",
      "\n",
      "Graphs:\n",
      "- Graph hetero(v0:v, v1:v, v2:v, v0v0:e, v1v1:e, v1v2:e, v2v0:e, v2v1:e, v2v2:e)\n",
      "Jobs:\n",
      "- CREATE LOADING JOB load_hetero_data FOR GRAPH hetero {\n",
      "DEFINE FILENAME v2v0_csv = \"./v2v0.csv\";\n",
      "DEFINE FILENAME v2v1_csv = \"./v2v1.csv\";\n",
      "DEFINE FILENAME v2v2_csv = \"./v2v2.csv\";\n",
      "DEFINE FILENAME v1_csv = \"./v1.csv\";\n",
      "DEFINE FILENAME v0v0_csv = \"./v0v0.csv\";\n",
      "DEFINE FILENAME v2_csv = \"./v2.csv\";\n",
      "DEFINE FILENAME v1v1_csv = \"./v1v1.csv\";\n",
      "DEFINE FILENAME v1v2_csv = \"./v1v2.csv\";\n",
      "DEFINE FILENAME v0_csv = \"./v0.csv\";\n",
      "LOAD v0_csv TO VERTEX v0 VALUES($\"id\", SPLIT($\"x\", \" \"), $\"y\", _, _, _) USING SEPARATOR=\",\", HEADER=\"true\", EOL=\"\\n\";\n",
      "LOAD v1_csv TO VERTEX v1 VALUES($\"id\", SPLIT($\"x\", \" \"), _, _, _) USING SEPARATOR=\",\", HEADER=\"true\", EOL=\"\\n\";\n",
      "LOAD v2_csv TO VERTEX v2 VALUES($\"id\", SPLIT($\"x\", \" \"), _, _, _) USING SEPARATOR=\",\", HEADER=\"true\", EOL=\"\\n\";\n",
      "LOAD v0v0_csv TO EDGE v0v0 VALUES($\"source\", $\"target\", _, _) USING SEPARATOR=\",\", HEADER=\"true\", EOL=\"\\n\";\n",
      "LOAD v1v1_csv TO EDGE v1v1 VALUES($\"source\", $\"target\", _, _) USING SEPARATOR=\",\", HEADER=\"true\", EOL=\"\\n\";\n",
      "LOAD v1v2_csv TO EDGE v1v2 VALUES($\"source\", $\"target\", _, _) USING SEPARATOR=\",\", HEADER=\"true\", EOL=\"\\n\";\n",
      "LOAD v2v0_csv TO EDGE v2v0 VALUES($\"source\", $\"target\", _, _) USING SEPARATOR=\",\", HEADER=\"true\", EOL=\"\\n\";\n",
      "LOAD v2v1_csv TO EDGE v2v1 VALUES($\"source\", $\"target\", _, _) USING SEPARATOR=\",\", HEADER=\"true\", EOL=\"\\n\";\n",
      "LOAD v2v2_csv TO EDGE v2v2 VALUES($\"source\", $\"target\", _, _) USING SEPARATOR=\",\", HEADER=\"true\", EOL=\"\\n\";\n",
      "}\n",
      "\n",
      "- CREATE SCHEMA_CHANGE JOB hetero_job FOR GRAPH hetero {\n",
      "ADD VERTEX v0(PRIMARY_ID id INT, x LIST<DOUBLE>, y INT, train_mask BOOL, val_mask BOOL, test_mask BOOL) WITH STATS=\"OUTDEGREE_BY_EDGETYPE\", PRIMARY_ID_AS_ATTRIBUTE=\"true\";\n",
      "ADD VERTEX v1(PRIMARY_ID id INT, x LIST<DOUBLE>, train_mask BOOL, val_mask BOOL, test_mask BOOL) WITH STATS=\"OUTDEGREE_BY_EDGETYPE\", PRIMARY_ID_AS_ATTRIBUTE=\"true\";\n",
      "ADD VERTEX v2(PRIMARY_ID id INT, x LIST<DOUBLE>, train_mask BOOL, val_mask BOOL, test_mask BOOL) WITH STATS=\"OUTDEGREE_BY_EDGETYPE\", PRIMARY_ID_AS_ATTRIBUTE=\"true\";\n",
      "ADD DIRECTED EDGE v0v0(FROM v0, TO v0, is_train BOOL, is_val BOOL);\n",
      "ADD DIRECTED EDGE v1v1(FROM v1, TO v1, is_train BOOL, is_val BOOL);\n",
      "ADD DIRECTED EDGE v1v2(FROM v1, TO v2, is_train BOOL, is_val BOOL);\n",
      "ADD DIRECTED EDGE v2v0(FROM v2, TO v0, is_train BOOL, is_val BOOL);\n",
      "ADD DIRECTED EDGE v2v1(FROM v2, TO v1, is_train BOOL, is_val BOOL);\n",
      "ADD DIRECTED EDGE v2v2(FROM v2, TO v2, is_train BOOL, is_val BOOL);\n",
      "}\n",
      "\n",
      "Queries:\n",
      "- edge_loader_is_train_is_val(int num_batches, bool shuffle, string filter_by, set<string> e_types, string kafka_address, string kafka_topic, string security_protocol, string sasl_mechanism, string sasl_username, string sasl_password, string ssl_ca_location) (installed v2)\n",
      "- edge_nei_loader_x_y_train_mask_val_mask_test_mask_is_train(int num_batches, int num_neighbors, int num_hops, bool shuffle, string filter_by, set<string> v_types, set<string> e_types, set<string> seed_types, string kafka_address, string kafka_topic, string security_protocol, string sasl_mechanism, string sasl_username, string sasl_password, string ssl_ca_location) (installed v2)\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(conn.gsql(\"ls\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bbc3e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing and optimizing queries. It might take a minute if this is the first time you use this loader.\n",
      "Query installation finished.\n"
     ]
    }
   ],
   "source": [
    "loader = conn.gds.graphLoader(\n",
    "    v_in_feats={\"v0\": [\"x\"],\n",
    "                \"v1\": [\"x\"]},\n",
    "    v_out_labels={\"v0\": [\"y\"]},\n",
    "    v_extra_feats={\"v0\": [\"train_mask\", \"val_mask\", \"test_mask\"]},\n",
    "    e_extra_feats={\"v0v0\": [\"is_train\", \"is_val\"],\n",
    "                    \"v1v1\": [\"is_train\", \"is_val\"]},\n",
    "    batch_size=1024,\n",
    "    shuffle=False,\n",
    "    filter_by=None,\n",
    "    output_format=\"PyG\",\n",
    "    add_self_loop=False,\n",
    "    loader_id=None,\n",
    "    buffer_size=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "095d3c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Batch 0----\n",
      "HeteroData(\n",
      "  \u001b[1mv0\u001b[0m={\n",
      "    x=[76, 77],\n",
      "    y=[76],\n",
      "    train_mask=[76],\n",
      "    val_mask=[76],\n",
      "    test_mask=[76]\n",
      "  },\n",
      "  \u001b[1mv1\u001b[0m={ x=[110, 57] },\n",
      "  \u001b[1m(v0, v0v0, v0)\u001b[0m={\n",
      "    edge_index=[2, 413],\n",
      "    is_train=[413],\n",
      "    is_val=[413]\n",
      "  },\n",
      "  \u001b[1m(v1, v1v1, v1)\u001b[0m={\n",
      "    edge_index=[2, 558],\n",
      "    is_train=[558],\n",
      "    is_val=[558]\n",
      "  }\n",
      ")\n",
      "----Batch 1----\n",
      "HeteroData(\n",
      "  \u001b[1mv0\u001b[0m={\n",
      "    x=[76, 77],\n",
      "    y=[76],\n",
      "    train_mask=[76],\n",
      "    val_mask=[76],\n",
      "    test_mask=[76]\n",
      "  },\n",
      "  \u001b[1mv1\u001b[0m={ x=[110, 57] },\n",
      "  \u001b[1m(v0, v0v0, v0)\u001b[0m={\n",
      "    edge_index=[2, 297],\n",
      "    is_train=[297],\n",
      "    is_val=[297]\n",
      "  },\n",
      "  \u001b[1m(v1, v1v1, v1)\u001b[0m={\n",
      "    edge_index=[2, 486],\n",
      "    is_train=[486],\n",
      "    is_val=[486]\n",
      "  }\n",
      ")\n",
      "CPU times: user 70.4 ms, sys: 11 ms, total: 81.4 ms\n",
      "Wall time: 98.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i, batch in enumerate(loader):\n",
    "    print(\"----Batch {}----\".format(i))\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c381f5c-bc5d-435b-bfcc-5c2a6e9d1972",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Kafka를 통한 스트리밍 \n",
    "\n",
    "**Note**: Kafka 스트리밍 기능은 Enterprise Edition에서만 사용할 수 있습니다. 사용하려면 Enterprise Edition을 활성화해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e04855",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = TigerGraphConnection(\n",
    "    host=\"http://127.0.0.1\", # 데이터베이스 서버의 주소로 변경\n",
    "    graphname=\"hetero\",\n",
    "    username=\"tigergraph\",\n",
    "    password=\"tigergraph\",\n",
    "    gsqlSecret=\"\" # 2022년 7월 5일 이후에 생성된 TG 클라우드 DB에는 user/pass 대신 secret이 필요합니다.  \n",
    ")\n",
    "\n",
    "# 토큰 인증이 활성화된 경우 토큰을 가져오고 설정하려면 아래 주석을 제거하십시오.\n",
    "#conn.getToken(<secret>) # <secret>은 사용자 암호입니다. 자세한 내용은 https://docs.tigergraph.com/tigergraph-server/current/user-access/managing-credentials#_secrets를 참조하세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5191804f-acc6-45c1-a616-f4395db63036",
   "metadata": {},
   "source": [
    "#### 카프카(Kafka) 설정 \n",
    "여기에서 Kafka를 설정합니다. 구성되면 설정이 새로 생성된 모든 데이터 로더와 공유되며 각 로더에 대해 Kafka를 설정할 필요가 없습니다. 자세한 설정 은 공식 [문서](https://docs.tigergraph.com/pytigergraph/current/gds/gds#_configurekafka) 를 참조하십시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32785a4b-09b8-42b1-a45f-cd92121b2b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.gds.configureKafka(\n",
    "    kafka_address=\"127.0.0.1:9092\",\n",
    "    kafka_security_protocol=\"SASL_PLAINTEXT\",\n",
    "    kafka_sasl_mechanism=\"PLAIN\",\n",
    "    kafka_sasl_plain_username=\"your username\",\n",
    "    kafka_sasl_plain_password=\"your password\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28719c2a-364e-4337-8d4a-705d64bf219e",
   "metadata": {},
   "source": [
    "#### 하위 그래프(subgraphs) 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c06fbca-ce98-4dc3-a047-dc42bcbec5fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:kafka.coordinator.consumer:group_id is None: disabling auto-commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing and optimizing queries. It might take a minute if this is the first time you use this loader.\n",
      "Query installation finished.\n",
      "CPU times: user 55.7 ms, sys: 15.1 ms, total: 70.8 ms\n",
      "Wall time: 26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "graph_loader = conn.gds.graphLoader(\n",
    "    num_batches=10,\n",
    "    v_in_feats = [\"x\"],\n",
    "    v_out_labels = [\"y\"],\n",
    "    v_extra_feats = [\"train_mask\", \"val_mask\", \"test_mask\"],\n",
    "    e_in_feats=[\"time\"],\n",
    "    e_out_labels=[],\n",
    "    e_extra_feats=[\"is_train\", \"is_val\"],\n",
    "    output_format = \"PyG\",\n",
    "    shuffle=True,\n",
    "    filter_by=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5a69163-1358-4263-91e2-903978914871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Batch 0----\n",
      "Data(edge_index=[2, 1018], edge_feat=[1018], is_train=[1018], is_val=[1018], x=[1006, 1433], y=[1006], train_mask=[1006], val_mask=[1006], test_mask=[1006])\n",
      "----Batch 1----\n",
      "Data(edge_index=[2, 1036], edge_feat=[1036], is_train=[1036], is_val=[1036], x=[1226, 1433], y=[1226], train_mask=[1226], val_mask=[1226], test_mask=[1226])\n",
      "----Batch 2----\n",
      "Data(edge_index=[2, 1083], edge_feat=[1083], is_train=[1083], is_val=[1083], x=[1234, 1433], y=[1234], train_mask=[1234], val_mask=[1234], test_mask=[1234])\n",
      "----Batch 3----\n",
      "Data(edge_index=[2, 1074], edge_feat=[1074], is_train=[1074], is_val=[1074], x=[1263, 1433], y=[1263], train_mask=[1263], val_mask=[1263], test_mask=[1263])\n",
      "----Batch 4----\n",
      "Data(edge_index=[2, 1023], edge_feat=[1023], is_train=[1023], is_val=[1023], x=[1107, 1433], y=[1107], train_mask=[1107], val_mask=[1107], test_mask=[1107])\n",
      "----Batch 5----\n",
      "Data(edge_index=[2, 1072], edge_feat=[1072], is_train=[1072], is_val=[1072], x=[1040, 1433], y=[1040], train_mask=[1040], val_mask=[1040], test_mask=[1040])\n",
      "----Batch 6----\n",
      "Data(edge_index=[2, 1053], edge_feat=[1053], is_train=[1053], is_val=[1053], x=[1231, 1433], y=[1231], train_mask=[1231], val_mask=[1231], test_mask=[1231])\n",
      "----Batch 7----\n",
      "Data(edge_index=[2, 1052], edge_feat=[1052], is_train=[1052], is_val=[1052], x=[1238, 1433], y=[1238], train_mask=[1238], val_mask=[1238], test_mask=[1238])\n",
      "----Batch 8----\n",
      "Data(edge_index=[2, 1046], edge_feat=[1046], is_train=[1046], is_val=[1046], x=[1277, 1433], y=[1277], train_mask=[1277], val_mask=[1277], test_mask=[1277])\n",
      "----Batch 9----\n",
      "Data(edge_index=[2, 1099], edge_feat=[1099], is_train=[1099], is_val=[1099], x=[1161, 1433], y=[1161], train_mask=[1161], val_mask=[1161], test_mask=[1161])\n",
      "CPU times: user 19.7 s, sys: 864 ms, total: 20.5 s\n",
      "Wall time: 3.29 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i, batch in enumerate(graph_loader):\n",
    "    print(\"----Batch {}----\".format(i))\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afe99f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-9.m81",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-9:m81"
  },
  "interpreter": {
   "hash": "96daeecb52bbbb8e3aef04d2f9c6a1e01f271d07cea30059f3c558ef00b717d2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc-autonumbering": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
