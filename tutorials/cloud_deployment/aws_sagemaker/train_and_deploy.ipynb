{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "source_directory = \"gat_cora\"\n",
    "\n",
    "os.mkdir(\"./{}\".format(source_directory))\n",
    "os.mkdir(\"./{}/code\".format(source_directory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing gat_cora/code/model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $source_directory/code/model.py\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv\n",
    "\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self, num_features, num_layers, out_dim, dropout, hidden_dim, num_heads\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dropout = dropout\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        for i in range(num_layers):\n",
    "            in_units = num_features if i == 0 else hidden_dim * num_heads\n",
    "            out_units = out_dim if i == (num_layers - 1) else hidden_dim\n",
    "            heads = 1 if i == (num_layers - 1) else num_heads\n",
    "            self.layers.append(\n",
    "                GATConv(in_units, out_units, heads=heads, dropout=dropout)\n",
    "            )\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for layer in self.layers:\n",
    "            layer.reset_parameters()\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x.float(), data.edge_index\n",
    "        for layer in self.layers[:-1]:\n",
    "            x = layer(x, edge_index)\n",
    "            x = F.elu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.layers[-1](x, edge_index)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"model_name\": \"GAT\",\n",
    "    \"model_config\": {\n",
    "        \"num_features\": 1433, # Number of features on Cora vertices \n",
    "        \"out_dim\": 7,         # Number of classes in Cora\n",
    "        \"num_heads\": 8,       # Number of attention heads in GAT model\n",
    "        \"hidden_dim\": 8,      # Number of hidden units in GAT model\n",
    "        \"num_layers\": 2,      # Number of GAT layers in GAT model\n",
    "        \"dropout\": 0.6        # Dropout probability in GAT model\n",
    "    },\n",
    "    \"infer_loader_config\": {\n",
    "        \"v_in_feats\": [\"x\"],     # List of vertex features to be loaded\n",
    "        \"v_out_labels\": [\"y\"],   # List of vertex labels to be loaded\n",
    "        \"v_extra_feats\": [],     # Don't need any extra features for inference\n",
    "        \"output_format\": \"PyG\",  # Using Pytorch Geometric format\n",
    "        \"batch_size\": 64,        # Batch size for inference\n",
    "        \"num_neighbors\": 10,     # Number of neighbors per vertex\n",
    "        \"num_hops\": 2,           # How deep to go in the graph\n",
    "        \"shuffle\": False         # Don't shuffle the data\n",
    "    },\n",
    "    \"training_loader_config\": {\n",
    "        \"v_in_feats\": [\"x\"],\n",
    "        \"v_out_labels\": [\"y\"],\n",
    "        \"v_extra_feats\": [\"train_mask\",\"val_mask\",\"test_mask\"],\n",
    "        \"output_format\": \"PyG\",\n",
    "        \"batch_size\": 64, \n",
    "        \"num_neighbors\": 10, \n",
    "        \"num_hops\": 2,\n",
    "        \"shuffle\": True\n",
    "    },\n",
    "    \"optimizer_config\": {\n",
    "        \"lr\": 0.01,\n",
    "        \"weight_decay\": 5e-4,\n",
    "    },\n",
    "    \"connection_config\": {\n",
    "        \"host\": \"http://35.230.92.92\", \n",
    "        \"graphname\": \"Cora\", \n",
    "        \"username\": \"tigergraph\", \n",
    "        \"password\": \"tigergraph\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "json.dump(parameters, open(\"{}/code/config.json\".format(source_directory), \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/aws-sagemaker-endpoint/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(source_directory+\"/code\")\n",
    "\n",
    "import model\n",
    "GAT = getattr(model, parameters[\"model_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GAT(\n",
       "  (layers): ModuleList(\n",
       "    (0): GATConv(1433, 8, heads=8)\n",
       "    (1): GATConv(64, 7, heads=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gat = GAT(**parameters[\"model_config\"])\n",
    "gat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyTigerGraph import TigerGraphConnection\n",
    "\n",
    "conn = TigerGraphConnection(**parameters[\"connection_config\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = conn.gds.neighborLoader(\n",
    "    **parameters[\"training_loader_config\"],\n",
    "    filter_by=\"train_mask\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loader = conn.gds.neighborLoader(\n",
    "    **parameters[\"training_loader_config\"],\n",
    "    filter_by=\"val_mask\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = conn.gds.neighborLoader(\n",
    "    **parameters[\"training_loader_config\"],\n",
    "    filter_by=\"test_mask\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "gat.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    gat.parameters(), **parameters[\"optimizer_config\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pyTigerGraph.gds.metrics import Accumulator, Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train Batch 0, Loss 1.9899, Accuracy 0.2174\n",
      "Epoch 0, Train Batch 1, Loss 1.9629, Accuracy 0.2231\n",
      "Epoch 0, Train Batch 2, Loss 1.8993, Accuracy 0.2290\n",
      "Epoch 0, Valid Loss 1.6847, Valid Accuracy 0.5180\n",
      "Epoch 1, Train Batch 0, Loss 1.3743, Accuracy 0.6471\n",
      "Epoch 1, Train Batch 1, Loss 1.4057, Accuracy 0.5385\n",
      "Epoch 1, Train Batch 2, Loss 1.3765, Accuracy 0.5634\n",
      "Epoch 1, Valid Loss 1.4639, Valid Accuracy 0.6568\n",
      "Epoch 2, Train Batch 0, Loss 1.2153, Accuracy 0.7015\n",
      "Epoch 2, Train Batch 1, Loss 1.1691, Accuracy 0.6644\n",
      "Epoch 2, Train Batch 2, Loss 1.2200, Accuracy 0.6381\n",
      "Epoch 2, Valid Loss 1.3022, Valid Accuracy 0.6548\n",
      "Epoch 3, Train Batch 0, Loss 1.2570, Accuracy 0.6389\n",
      "Epoch 3, Train Batch 1, Loss 1.0519, Accuracy 0.6923\n",
      "Epoch 3, Train Batch 2, Loss 1.0468, Accuracy 0.6863\n",
      "Epoch 3, Valid Loss 1.1991, Valid Accuracy 0.6653\n",
      "Epoch 4, Train Batch 0, Loss 0.8330, Accuracy 0.7164\n",
      "Epoch 4, Train Batch 1, Loss 0.8263, Accuracy 0.7333\n",
      "Epoch 4, Train Batch 2, Loss 0.8301, Accuracy 0.7404\n",
      "Epoch 4, Valid Loss 1.1072, Valid Accuracy 0.6651\n",
      "Epoch 5, Train Batch 0, Loss 0.9428, Accuracy 0.7500\n",
      "Epoch 5, Train Batch 1, Loss 0.9300, Accuracy 0.7344\n",
      "Epoch 5, Train Batch 2, Loss 0.9366, Accuracy 0.7238\n",
      "Epoch 5, Valid Loss 1.0556, Valid Accuracy 0.6861\n",
      "Epoch 6, Train Batch 0, Loss 0.7418, Accuracy 0.7681\n",
      "Epoch 6, Train Batch 1, Loss 0.7043, Accuracy 0.7842\n",
      "Epoch 6, Train Batch 2, Loss 0.7285, Accuracy 0.7689\n",
      "Epoch 6, Valid Loss 1.0227, Valid Accuracy 0.6718\n",
      "Epoch 7, Train Batch 0, Loss 0.7886, Accuracy 0.7162\n",
      "Epoch 7, Train Batch 1, Loss 0.7304, Accuracy 0.7376\n",
      "Epoch 7, Train Batch 2, Loss 0.7597, Accuracy 0.7236\n",
      "Epoch 7, Valid Loss 1.0198, Valid Accuracy 0.6849\n",
      "Epoch 8, Train Batch 0, Loss 0.8293, Accuracy 0.8226\n",
      "Epoch 8, Train Batch 1, Loss 0.7435, Accuracy 0.8062\n",
      "Epoch 8, Train Batch 2, Loss 0.7006, Accuracy 0.8038\n",
      "Epoch 8, Valid Loss 1.0215, Valid Accuracy 0.6900\n",
      "Epoch 9, Train Batch 0, Loss 0.6994, Accuracy 0.7576\n",
      "Epoch 9, Train Batch 1, Loss 0.7981, Accuracy 0.7536\n",
      "Epoch 9, Train Batch 2, Loss 0.8144, Accuracy 0.7847\n",
      "Epoch 9, Valid Loss 1.0095, Valid Accuracy 0.6943\n"
     ]
    }
   ],
   "source": [
    "global_steps = 0\n",
    "logs = {}\n",
    "for epoch in range(10):\n",
    "    # Train\n",
    "    gat.train()\n",
    "    epoch_train_loss = Accumulator()\n",
    "    epoch_train_acc = Accuracy()\n",
    "    for bid, batch in enumerate(train_loader):\n",
    "        batchsize = batch.x.shape[0]\n",
    "        batch.to(device)\n",
    "        # Forward pass\n",
    "        out = gat(batch)\n",
    "        # Calculate loss\n",
    "        loss = F.cross_entropy(out[batch.train_mask], batch.y[batch.train_mask])\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_train_loss.update(loss.item() * batchsize, batchsize)\n",
    "        # Predict on training data\n",
    "        with torch.no_grad():\n",
    "            pred = out.argmax(dim=1)\n",
    "            epoch_train_acc.update(pred[batch.train_mask], batch.y[batch.train_mask])\n",
    "        # Log training status after each batch\n",
    "        logs[\"loss\"] = epoch_train_loss.mean\n",
    "        logs[\"acc\"] = epoch_train_acc.value\n",
    "        print(\n",
    "            \"Epoch {}, Train Batch {}, Loss {:.4f}, Accuracy {:.4f}\".format(\n",
    "                epoch, bid, logs[\"loss\"], logs[\"acc\"]\n",
    "            )\n",
    "        )\n",
    "        global_steps += 1\n",
    "    # Evaluate\n",
    "    gat.eval()\n",
    "    epoch_val_loss = Accumulator()\n",
    "    epoch_val_acc = Accuracy()\n",
    "    for batch in valid_loader:\n",
    "        batchsize = batch.x.shape[0]\n",
    "        batch.to(device)\n",
    "        with torch.no_grad():\n",
    "            # Forward pass\n",
    "            out = gat(batch)\n",
    "            # Calculate loss\n",
    "            valid_loss = F.cross_entropy(out[batch.val_mask], batch.y[batch.val_mask])\n",
    "            epoch_val_loss.update(valid_loss.item() * batchsize, batchsize)\n",
    "            # Prediction\n",
    "            pred = out.argmax(dim=1)\n",
    "            epoch_val_acc.update(pred[batch.val_mask], batch.y[batch.val_mask])\n",
    "    # Log testing result after each epoch\n",
    "    logs[\"val_loss\"] = epoch_val_loss.mean\n",
    "    logs[\"val_acc\"] = epoch_val_acc.value\n",
    "    print(\n",
    "        \"Epoch {}, Valid Loss {:.4f}, Valid Accuracy {:.4f}\".format(\n",
    "            epoch, logs[\"val_loss\"], logs[\"val_acc\"]\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7204\n"
     ]
    }
   ],
   "source": [
    "gat.eval()\n",
    "acc = Accuracy()\n",
    "for batch in test_loader:\n",
    "    batch.to(device)\n",
    "    with torch.no_grad():\n",
    "        pred = gat(batch).argmax(dim=1)\n",
    "        acc.update(pred[batch.test_mask], batch.y[batch.test_mask])\n",
    "print(\"Accuracy: {:.4f}\".format(acc.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(gat.state_dict(), \"{}/model.pth\".format(source_directory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting gat_cora/code/inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $source_directory/code/inference.py\n",
    "import torch\n",
    "import pyTigerGraph as tg\n",
    "import json\n",
    "import model\n",
    "import os\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    with open(os.path.join(model_dir, \"code/config.json\")) as json_file:\n",
    "        config = json.load(json_file)\n",
    "    connection_config = config[\"connection_config\"]\n",
    "    model_config = config[\"model_config\"]\n",
    "    loader_config = config[\"infer_loader_config\"]\n",
    "    model_name = config[\"model_name\"]\n",
    "\n",
    "    mdl = getattr(model, model_name)\n",
    "\n",
    "    conn = tg.TigerGraphConnection(**connection_config)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    gnn_model = mdl(**model_config)\n",
    "    with open(os.path.join(model_dir, \"model.pth\"), 'rb') as f:\n",
    "        gnn_model.load_state_dict(torch.load(f))\n",
    "    gnn_model.to(device).eval()\n",
    "\n",
    "    infer_loader = conn.gds.neighborLoader(**loader_config)\n",
    "\n",
    "    model_loader_dict = {\"model\": gnn_model, \"loader\": infer_loader}\n",
    "\n",
    "    return model_loader_dict\n",
    "    \n",
    "def input_fn(request_body, content_type=\"application/json\"):\n",
    "    if content_type == \"application/json\":\n",
    "        input_data = json.loads(request_body)\n",
    "        verts = input_data[\"vertices\"]\n",
    "        return verts\n",
    "    else:\n",
    "        raise Exception(\"Requested unsupported ContentType in content_type: {}\".format(content_type))\n",
    "\n",
    "def predict_fn(input_data, model):\n",
    "    loader = model[\"loader\"]\n",
    "    gnn = model[\"model\"]\n",
    "    sub_graphs = loader.fetch(input_data)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    sub_graphs.to(device)\n",
    "    with torch.no_grad():\n",
    "        output = gnn(sub_graphs)\n",
    "    return (input_data, output.cpu())\n",
    "\n",
    "def output_fn(prediction, content_type):\n",
    "    if content_type == \"application/json\":\n",
    "        returnJson = {}\n",
    "        for i in range(len(prediction[0])):\n",
    "            returnJson[prediction[0][i][\"primary_id\"]] = list(prediction[1][i].tolist())\n",
    "        return json.dumps(returnJson)\n",
    "    raise Exception(\"Requested unsupported ContentType in content_type: {}\".format(content_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing gat_cora/code/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile $source_directory/code/requirements.txt\n",
    "pyTigerDriver==1.0.14\n",
    "pyTigerGraph[gds]==0.9\n",
    "torch-geometric==2.0.4\n",
    "torch-scatter==2.0.9\n",
    "torch-sparse==0.6.13\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "\n",
    "zipped_model_path = \"./model.tar.gz\"\n",
    "\n",
    "with tarfile.open(zipped_model_path, \"w:gz\") as tar:\n",
    "    tar.add(source_directory+\"/model.pth\")\n",
    "    tar.add(source_directory+\"/code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "\n",
    "role = \"AmazonSageMaker-ExecutionRole-20211022T101209\"\n",
    "\n",
    "pytorch_model = PyTorchModel(model_data=\"s3://tg-mlworkbench/sagemaker_inference/model.tar.gz\", \n",
    "                             role=role,\n",
    "                             source_dir=\"s3://tg-mlworkbench/sagemaker_inference/model.tar.gz\",\n",
    "                             entry_point='code/inference.py', \n",
    "                             py_version='py38', \n",
    "                             framework_version='1.11.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----!"
     ]
    }
   ],
   "source": [
    "predictor = pytorch_model.deploy(initial_instance_count=1, \n",
    "                         instance_type='ml.m5.xlarge', \n",
    "                         endpoint_name=\"gat-cora-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gat-cora-4'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModelError",
     "evalue": "An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (0) from primary with message \"Your invocation timed out while waiting for a response from container primary. Review the latency metrics for each container in Amazon CloudWatch, resolve the issue, and try again.\". See https://us-east-2.console.aws.amazon.com/cloudwatch/home?region=us-east-2#logEventViewer:group=/aws/sagemaker/Endpoints/gat-cora-4 in account 090082397457 for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModelError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/parkererickson/mlworkbench-docs/tutorials/cloud_deployment/aws_sagemaker/train_and_deploy.ipynb Cell 22'\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/parkererickson/mlworkbench-docs/tutorials/cloud_deployment/aws_sagemaker/train_and_deploy.ipynb#ch0000021?line=7'>8</a>\u001b[0m payload \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mdumps(payload)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/parkererickson/mlworkbench-docs/tutorials/cloud_deployment/aws_sagemaker/train_and_deploy.ipynb#ch0000021?line=8'>9</a>\u001b[0m predictor \u001b[39m=\u001b[39m Predictor(predictor\u001b[39m.\u001b[39mendpoint_name)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/parkererickson/mlworkbench-docs/tutorials/cloud_deployment/aws_sagemaker/train_and_deploy.ipynb#ch0000021?line=9'>10</a>\u001b[0m inference_response \u001b[39m=\u001b[39m predictor\u001b[39m.\u001b[39;49mpredict(data\u001b[39m=\u001b[39;49mpayload)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/parkererickson/mlworkbench-docs/tutorials/cloud_deployment/aws_sagemaker/train_and_deploy.ipynb#ch0000021?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m (inference_response)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/aws-sagemaker-endpoint/lib/python3.9/site-packages/sagemaker/predictor.py:161\u001b[0m, in \u001b[0;36mPredictor.predict\u001b[0;34m(self, data, initial_args, target_model, target_variant, inference_id)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[39m\"\"\"Return the inference from the specified endpoint.\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \n\u001b[1;32m    133\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[39m        as is.\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    158\u001b[0m request_args \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_request_args(\n\u001b[1;32m    159\u001b[0m     data, initial_args, target_model, target_variant, inference_id\n\u001b[1;32m    160\u001b[0m )\n\u001b[0;32m--> 161\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msagemaker_session\u001b[39m.\u001b[39;49msagemaker_runtime_client\u001b[39m.\u001b[39;49minvoke_endpoint(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mrequest_args)\n\u001b[1;32m    162\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_response(response)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/aws-sagemaker-endpoint/lib/python3.9/site-packages/botocore/client.py:508\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    504\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    505\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpy_operation_name\u001b[39m}\u001b[39;00m\u001b[39m() only accepts keyword arguments.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    506\u001b[0m     )\n\u001b[1;32m    507\u001b[0m \u001b[39m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 508\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_api_call(operation_name, kwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/aws-sagemaker-endpoint/lib/python3.9/site-packages/botocore/client.py:911\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    909\u001b[0m     error_code \u001b[39m=\u001b[39m parsed_response\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mError\u001b[39m\u001b[39m\"\u001b[39m, {})\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mCode\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    910\u001b[0m     error_class \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m--> 911\u001b[0m     \u001b[39mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m    912\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    913\u001b[0m     \u001b[39mreturn\u001b[39;00m parsed_response\n",
      "\u001b[0;31mModelError\u001b[0m: An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (0) from primary with message \"Your invocation timed out while waiting for a response from container primary. Review the latency metrics for each container in Amazon CloudWatch, resolve the issue, and try again.\". See https://us-east-2.console.aws.amazon.com/cloudwatch/home?region=us-east-2#logEventViewer:group=/aws/sagemaker/Endpoints/gat-cora-4 in account 090082397457 for more information."
     ]
    }
   ],
   "source": [
    "from sagemaker.predictor import Predictor\n",
    "import json\n",
    "\n",
    "# Read image into memory\n",
    "payload = {\"vertices\": [{\"primary_id\": \"1\", \"type\": \"Paper\"}]}\n",
    "\n",
    "\n",
    "payload = json.dumps(payload)\n",
    "predictor = Predictor(predictor.endpoint_name)\n",
    "inference_response = predictor.predict(data=payload)\n",
    "print (inference_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a4096bdfbcbac04d93e5d367b885741d6357cbebe92957072fd1a74a372c2e06"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('aws-sagemaker-endpoint')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
