{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95bf38d0-4c66-4fe9-adb4-ba2668491f59",
   "metadata": {},
   "source": [
    "# LightGCN for Recommendation\n",
    "This notebook demonstrates the training of LightGCN (https://arxiv.org/abs/2002.02126) for Recommendation with TigerGraph. Pytorch Geometric's implementation of LightGCN is used here. We train the model on the LastFM dataset from PyG datasets with TigerGraph as the data store. The dataset contains 1,892 users, 17,632 items and 92,834 edges between users and items. And the dataset is already splitted into train and test sets. The metric for evaluation is recall@k.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03badfe2-7a7a-4235-a06e-f63ba3c61871",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "Here we assume the dataset is already ingested into the TigerGraph database. If not, please refer to the example on data ingestion first.\n",
    "\n",
    "For each edge, the attributes include \"is_train, is_test\". For each node, the attribute **role is 0 or 1** indicates the node is user or item."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89efdc94-bb17-41f2-a9bb-5aa29f9a2991",
   "metadata": {},
   "source": [
    "## Connect to TigerGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f29b77f1-625b-4765-8b2b-5b0135c74f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyTigerGraph import TigerGraphConnection\n",
    "import torch\n",
    "\n",
    "conn = TigerGraphConnection(\n",
    "    host=\"http://127.0.0.1\", # Change the address to your database server's\n",
    "    graphname=\"LastFM\",\n",
    "    username=\"tigergraph\",\n",
    "    password=\"tigergraph\",\n",
    "    useCert=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8f404f2-5799-44a1-9307-ec4ae54bc05e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'User': 1892, 'Item': 17632}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.getVertexCount(\"*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4416bcb9-51eb-4c88-a73f-3908eeeacad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Interact': 92834}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.getEdgeCount('*')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47478046-fa3e-408d-9a70-4a0903906fd6",
   "metadata": {},
   "source": [
    "## Train on whole graph\n",
    "Here, we use the full graph for recommendation. This will NOT work when the graph is very large. See the section of Stochastic training for huge graphs. However, we still include this example for illustration purpose.\n",
    "\n",
    "We load the whole graph from TigerGraph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d39ada4-6f34-4ec2-a901-bcd914f74616",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_loader = conn.gds.graphLoader(\n",
    "    num_batches=1,\n",
    "    v_extra_feats=[\"role\", 'id'],\n",
    "    e_extra_feats=[\"is_train\",\"is_test\"],\n",
    "    output_format = \"PyG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c96032-8e67-474e-9fd7-a918e0a81f42",
   "metadata": {},
   "source": [
    "**Note**: After the graphloader, the nodes' id is reindexed. This dataset don't contains node "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a28dcc3-be77-42f3-be7a-925e6856bee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = graph_loader.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ab3a340-e795-4e49-b5c7-44b7c3444585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 185668], is_train=[185668], is_test=[185668], role=[19524], id=[19524])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4074ea8b-4960-49e6-8ca7-eafb8cdc249d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user_item = data.edge_index[:, data.is_train]\n",
    "test_user_item = data.edge_index[:, data.is_test]\n",
    "train_user_item = train_user_item[:, data.role[train_user_item[0]] == 0]\n",
    "test_user_item = test_user_item[:, data.role[test_user_item[0]] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "65ab991d-ac2f-4d05-8e54-aefadd645c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = (data.role == 0).nonzero().squeeze().tolist()\n",
    "items = (data.role == 1).nonzero().squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febdf031-fb2d-494b-bdf3-5c71321ba6ed",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "We use recall@k to evaluate the performace. Specifically, for each user, we rank all items based on the scores, and then caculate the test recall@k from top k items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5cab8b51-c8e6-4e74-90f5-e6cd1d89d915",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_record(user_item, users):\n",
    "    user_record = {}\n",
    "    for u in users:\n",
    "        user_record[u] = user_item[1][user_item[0]==u].tolist()\n",
    "    return user_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3cd2031f-b41b-4ea6-9705-c25e0d117068",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user_record = get_user_record(train_user_item, users)\n",
    "test_user_record = get_user_record(test_user_item, users)\n",
    "# The user record is {user1:[item1, item2], user2:[], ...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "92327df3-8d3a-4ff9-994f-e7cef6930fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "61cb7745-ad5e-4208-8f80-31c098f13a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recallk(embeddings, items, train_user_record, test_user_record):\n",
    "    k_list = [2, 5, 10, 30]\n",
    "    recall = defaultdict(list)\n",
    "    items = torch.LongTensor(items)\n",
    "    items_vec = embeddings[items]\n",
    "    for user, test_items in test_user_record.items():\n",
    "        if len(test_items) == 0:\n",
    "            continue\n",
    "        user_vec = embeddings[user]\n",
    "        scores = torch.sum(user_vec * items_vec, dim=1)\n",
    "        scores, indices = torch.topk(scores, 200)\n",
    "        predict_items = items[indices].numpy()\n",
    "        predict_items = [i for i in predict_items if i not in train_user_record[user]]\n",
    "        # Filter out the items already in the training set\n",
    "        for k in k_list:\n",
    "            num = len(set(test_items) & set(predict_items[:k]))\n",
    "            recall[k].append(num / len(test_items))\n",
    "    for k in k_list:\n",
    "        print('recall@{}:, {}'.format(k, sum(recall[k])/len(recall[k])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a0cf9a-baaf-4b34-8f62-e815344ac2a8",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "We use LightGCN as our model, and the BPR loss function. For more details, please refer https://arxiv.org/abs/2002.02126."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6edb381b-b3e3-4506-89d8-ac96b0eb765a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Embedding, ModuleList\n",
    "from torch_geometric.nn import LGConv\n",
    "\n",
    "\n",
    "class LightGCN(torch.nn.Module):\n",
    "    def __init__(self, num_nodes, embedding_dim, num_layers, dropout, **kwargs):\n",
    "        super(LightGCN, self).__init__()\n",
    "        self.num_nodes = num_nodes\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.alpha = torch.tensor([1.0/(num_layers + 1)] * (num_layers + 1))\n",
    "        self.embedding = Embedding(num_nodes, embedding_dim)\n",
    "        self.convs = torch.nn.ModuleList([LGConv(**kwargs) for _ in range(num_layers)])\n",
    "        self.dropout = dropout\n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        torch.nn.init.normal_(self.embedding.weight, std=0.1)\n",
    "        # torch.nn.init.xavier_uniform_(self.embedding.weight)\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "            \n",
    "    def forward(self, edge_index, nodes):\n",
    "        x = self.embedding(nodes)\n",
    "        out = x * self.alpha[0]\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.convs[i](x, edge_index)\n",
    "            out = out + x * self.alpha[i + 1]\n",
    "        return out\n",
    "\n",
    "    def decode(self, z, users, pos_items, neg_items):\n",
    "        pos_scores = (z[users] * z[pos_items]).sum(dim=-1)\n",
    "        neg_scores = (z[users] * z[neg_items]).sum(dim=-1)\n",
    "        # BPR Loss\n",
    "        maxi = F.logsigmoid(pos_scores - neg_scores)\n",
    "        loss = -maxi.mean()\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78434a8-a202-41dd-8896-2c3d51b3c41d",
   "metadata": {},
   "source": [
    "## Train the model using the whole graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eed4fe35-95e0-4fdd-8d94-25cc98b5077a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "hp = {\"embedding_dim\": 64, \"num_layers\": 2, \"dropout\": 0.6, \"lr\": 0.001, \"l2_penalty\": 1e-5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0e195cf4-699e-4426-8fe2-93ceee7d8721",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = sum(conn.getVertexCount(\"*\").values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "05f8d08b-77b7-42e1-b690-e173a29c4458",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LightGCN(num_nodes, hp['embedding_dim'], hp['num_layers'], hp['dropout'])\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr=hp[\"lr\"], weight_decay=hp[\"l2_penalty\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "52d5e8c3-6d96-41aa-a21a-d103f545650b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_edge_index = data.edge_index[:, data.is_train]\n",
    "test_edge_index = data.edge_index[:, data.is_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cf405e20-985c-4872-83b0-520493dd099a",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_pos_index = train_edge_index[:, data.role[train_edge_index[0]] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4e5a753f-c3d0-4e57-9ca1-84539578a3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8dbf8540-0884-467a-9d86-1238da927b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, training loss: 0.6881372928619385\n",
      "recall@2:, 0.00013700838168923275\n",
      "recall@5:, 0.00029658284977433915\n",
      "recall@10:, 0.0005121120014737035\n",
      "recall@30:, 0.0022509636448935573\n",
      "Epoch: 40, training loss: 0.29866740852594376\n",
      "recall@2:, 0.03901264710987819\n",
      "recall@5:, 0.06873777301303904\n",
      "recall@10:, 0.10054871127836525\n",
      "recall@30:, 0.1772820576323309\n",
      "Epoch: 80, training loss: 0.20639914646744728\n",
      "recall@2:, 0.040543566171695265\n",
      "recall@5:, 0.07484413952929295\n",
      "recall@10:, 0.11180803164368167\n",
      "recall@30:, 0.19327400117238122\n",
      "Epoch: 120, training loss: 0.18053408712148666\n",
      "recall@2:, 0.04218936917622792\n",
      "recall@5:, 0.08059376298503335\n",
      "recall@10:, 0.11900254412605393\n",
      "recall@30:, 0.20621602286401142\n",
      "Epoch: 160, training loss: 0.16577080264687538\n",
      "recall@2:, 0.04614484211206697\n",
      "recall@5:, 0.0848391269737443\n",
      "recall@10:, 0.12585340720227683\n",
      "recall@30:, 0.21683980545744358\n",
      "Epoch: 200, training loss: 0.15787839516997337\n",
      "recall@2:, 0.04756660002318656\n",
      "recall@5:, 0.08793789972442569\n",
      "recall@10:, 0.1315548363329102\n",
      "recall@30:, 0.22518635296153158\n"
     ]
    }
   ],
   "source": [
    "batch_size = 20000\n",
    "pos_users = user_pos_index[0]\n",
    "pos_items = user_pos_index[1]\n",
    "for epoch in range(201):\n",
    "    model.train()\n",
    "    neg_items = items[torch.randint(len(items), (pos_items.shape[0],))]\n",
    "    # print(h.shape)\n",
    "    total_loss = 0\n",
    "    count = 0\n",
    "    for perm in DataLoader(range(pos_users.size(0)), batch_size,\n",
    "                           shuffle=True):\n",
    "        optimizer.zero_grad()\n",
    "        h = model(train_edge_index, torch.LongTensor(range(0, num_nodes)))\n",
    "        loss = model.decode(h, pos_users[perm], pos_items[perm], neg_items[perm])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        count += 1\n",
    "    if epoch % 40 == 0:\n",
    "        print('Epoch: {}, training loss: {}'.format(epoch, total_loss / count))\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            h = model(train_edge_index, torch.LongTensor(range(0, num_nodes)))\n",
    "            recallk(h, items, train_user_record, test_user_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77d0cd2-076f-40b5-863a-537869a1d1d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d076db5d-9007-43a2-b57e-7b899002e728",
   "metadata": {},
   "source": [
    "## Stochastic Training\n",
    "For stochastic training, we split the training edges into batches. At each specific batch, to do the recommendation, we need to know the neighbor graph for the each pair of nodes that has a edge.\n",
    "We use the edgeNeighborLoader, which can load the neghbors of the pair nodes of a edge and has same parameters as neighborLoader()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6a3dc684-6d77-4a3c-9263-8c43a3ff7c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_edge_neighbor_loader = conn.gds.edgeNeighborLoader(\n",
    "    v_extra_feats=[\"id\", \"role\"],\n",
    "    num_batches=5,\n",
    "    e_extra_feats=[\"is_train\", \"is_test\"],\n",
    "    output_format=\"PyG\",\n",
    "    num_neighbors=10,\n",
    "    num_hops=2,\n",
    "    filter_by=\"is_train\",\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87998c1-53e1-432e-839c-4017186b9bb0",
   "metadata": {},
   "source": [
    "### Use the Whole graph for recall\n",
    "As we use recall as the evaluation metric, we need to get the user_record.\n",
    "\n",
    "The Whole graph won't be used for training and inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "105e71da-3fc5-40ca-af94-624342c4bdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_loader = conn.gds.graphLoader(\n",
    "    num_batches=1,\n",
    "    v_extra_feats=[\"role\", 'id'],\n",
    "    e_extra_feats=[\"is_train\",\"is_test\"],\n",
    "    output_format = \"PyG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ac5f4c24-63e9-4f6d-a187-4f46391a9a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = graph_loader.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "817aa191-1995-4c58-aead-efdfdb5cfbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user_item = data.edge_index[:, data.is_train]\n",
    "test_user_item = data.edge_index[:, data.is_test]\n",
    "train_user_item = train_user_item[:, data.role[train_user_item[0]] == 0]\n",
    "test_user_item = test_user_item[:, data.role[test_user_item[0]] == 0]\n",
    "train_user_item_id = data.id[train_user_item]\n",
    "test_user_item_id = data.id[test_user_item]\n",
    "users_id = data.id[data.role==0].tolist()\n",
    "items_id = data.id[data.role==1].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6724cdb4-dc28-4d53-a773-3f14e569b7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_record(user_item, users):\n",
    "    user_record = {}\n",
    "    for u in users:\n",
    "        user_record[u] = user_item[1][user_item[0]==u].tolist()\n",
    "    return user_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4b1c439d-ff9f-43f4-b55b-40dd3b937ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user_record = get_user_record(train_user_item_id, users_id)\n",
    "test_user_record = get_user_record(test_user_item_id, users_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d300dc-ed72-4ea9-a17e-b5972a043f60",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dd14ed96-d66a-4612-ba8e-97a7558190e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LightGCN(num_nodes, hp['embedding_dim'], hp['num_layers'], hp['dropout'])\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr=hp[\"lr\"], weight_decay=hp[\"l2_penalty\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e1999752-14da-48f1-9743-c6cbc337b306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, training loss: 3.4278719425201416\n",
      "Epoch: 20, training loss: 2.4438130855560303\n",
      "Epoch: 40, training loss: 1.4304150640964508\n",
      "Epoch: 60, training loss: 1.1493873298168182\n",
      "Epoch: 80, training loss: 1.0042845904827118\n",
      "Epoch: 100, training loss: 0.9102801829576492\n",
      "Epoch: 120, training loss: 0.8601862490177155\n",
      "Epoch: 140, training loss: 0.8185435086488724\n",
      "Epoch: 160, training loss: 0.777618020772934\n",
      "Epoch: 180, training loss: 0.7471616566181183\n",
      "Epoch: 200, training loss: 0.7317674607038498\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(201):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for bid, batch in enumerate(train_edge_neighbor_loader):\n",
    "        # get the training edges and negative edges sampled in the same batch\n",
    "        train_edges = batch.edge_index[:, batch.is_seed]\n",
    "        items = (batch.role == 1).nonzero().squeeze()\n",
    "        users2items = train_edges[:, batch.role[train_edges[0]] == 0]\n",
    "        users = users2items[0]\n",
    "        pos_items = users2items[1]\n",
    "        neg_items = items[torch.randint(len(items), (pos_items.shape[0],))]\n",
    "        nodes_id = batch.id\n",
    "        train_graph_edges = batch.edge_index[:, batch.is_train]\n",
    "        optimizer.zero_grad()\n",
    "        h = model(train_graph_edges, nodes_id)\n",
    "        loss = model.decode(h, users, pos_items, neg_items)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() \n",
    "    if epoch % 20 == 0:\n",
    "        print('Epoch: {}, training loss: {}'.format(epoch, total_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261bac78-7a79-4aa1-912a-cf192bc6fb11",
   "metadata": {},
   "source": [
    "### Get nodes' embedding\n",
    "Use neighbor loader to get the embedding of each node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e4902436-2653-4ff0-b15c-bf006607242a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing and optimizing queries. It might take a minute if this is the first time you use this loader.\n",
      "Query installation finished.\n"
     ]
    }
   ],
   "source": [
    "neighbor_loader = conn.gds.neighborLoader(\n",
    "    v_extra_feats=[\"id\", \"role\"],\n",
    "    num_batches=5,\n",
    "    e_extra_feats=[\"is_train\", \"is_test\"],\n",
    "    output_format=\"PyG\",\n",
    "    num_neighbors=10,\n",
    "    num_hops=2,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "41f343d3-445c-4bb7-a3b0-73e685adbe21",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def infer(model, neighbor_loader):\n",
    "    embeddings = torch.zeros(num_nodes, hp['embedding_dim'])\n",
    "    model.eval()\n",
    "    for bid, batch in enumerate(neighbor_loader):\n",
    "        train_graph_edges = batch.edge_index[:, batch.is_train]\n",
    "        nodes_id = batch.id\n",
    "        is_seed = batch.is_seed\n",
    "        h = model(train_graph_edges, nodes_id)\n",
    "        embeddings[nodes_id[is_seed]] = h[is_seed]\n",
    "    print(embeddings)\n",
    "    return embeddings\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7a84c495-26b0-4c87-9a49-72858e42231a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1570, -0.1485,  0.0248,  ..., -0.2449,  0.1912, -0.2190],\n",
      "        [-0.2568,  0.3872,  0.4651,  ...,  0.2266, -0.1529,  0.1842],\n",
      "        [ 0.2613, -0.2763, -0.1870,  ..., -0.2249,  0.2745, -0.3259],\n",
      "        ...,\n",
      "        [ 0.0124,  0.0258,  0.0468,  ...,  0.0222, -0.0103, -0.0133],\n",
      "        [ 0.0125,  0.0272,  0.0489,  ...,  0.0214, -0.0121, -0.0113],\n",
      "        [ 0.0100, -0.0144, -0.0210,  ..., -0.0118,  0.0021, -0.0202]])\n"
     ]
    }
   ],
   "source": [
    "embeddigns = infer(model, neighbor_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "500a4bfe-058c-4bc3-b685-8330f5f6b37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall@2:, 0.042619458636972425\n",
      "recall@5:, 0.08181410490295786\n",
      "recall@10:, 0.12334695609084659\n",
      "recall@30:, 0.22187967001928496\n"
     ]
    }
   ],
   "source": [
    "recallk(embeddigns, items_id, train_user_record, test_user_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2a724a-b7dc-4ddf-b187-c2c110d17cdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c0642f-ea11-4e0e-ab0b-4afee9931f04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TigerGraph Pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
